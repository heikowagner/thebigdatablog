 INFO [2020-01-12 12:15:26,177] ({Thread-0} RemoteInterpreterServer.java[run]:97) - Starting remote interpreter server on port 35619
 INFO [2020-01-12 12:15:27,487] ({pool-1-thread-2} RemoteInterpreterServer.java[createInterpreter]:198) - Instantiate interpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2020-01-12 12:15:27,537] ({pool-1-thread-2} RemoteInterpreterServer.java[createInterpreter]:198) - Instantiate interpreter org.apache.zeppelin.spark.SparkSqlInterpreter
 INFO [2020-01-12 12:15:27,558] ({pool-1-thread-2} RemoteInterpreterServer.java[createInterpreter]:198) - Instantiate interpreter org.apache.zeppelin.spark.DepInterpreter
 INFO [2020-01-12 12:15:27,618] ({pool-1-thread-2} RemoteInterpreterServer.java[createInterpreter]:198) - Instantiate interpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2020-01-12 12:15:27,623] ({pool-1-thread-2} RemoteInterpreterServer.java[createInterpreter]:198) - Instantiate interpreter org.apache.zeppelin.spark.SparkRInterpreter
 INFO [2020-01-12 12:15:27,786] ({pool-2-thread-2} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578831327784 started by scheduler org.apache.zeppelin.spark.SparkInterpreter2057123742
 INFO [2020-01-12 12:15:41,592] ({pool-2-thread-2} SparkInterpreter.java[createSparkSession]:318) - ------ Create new SparkContext local[*] -------
 WARN [2020-01-12 12:15:41,616] ({pool-2-thread-2} SparkInterpreter.java[setupConfForSparkR]:562) - sparkr.zip is not found, sparkr may not work.
 INFO [2020-01-12 12:15:45,448] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Running Spark version 2.1.0
 WARN [2020-01-12 12:15:49,646] ({pool-2-thread-2} NativeCodeLoader.java[<clinit>]:62) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 WARN [2020-01-12 12:15:49,890] ({pool-2-thread-2} Logging.scala[logWarning]:66) - 
SPARK_CLASSPATH was detected (set to ':/zeppelin/interpreter/spark/dep/*:/zeppelin/interpreter/spark/*:/zeppelin/lib/interpreter/*:').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
 WARN [2020-01-12 12:15:49,894] ({pool-2-thread-2} Logging.scala[logWarning]:66) - Setting 'spark.executor.extraClassPath' to ':/zeppelin/interpreter/spark/dep/*:/zeppelin/interpreter/spark/*:/zeppelin/lib/interpreter/*:' as a work-around.
 WARN [2020-01-12 12:15:49,896] ({pool-2-thread-2} Logging.scala[logWarning]:66) - Setting 'spark.driver.extraClassPath' to ':/zeppelin/interpreter/spark/dep/*:/zeppelin/interpreter/spark/*:/zeppelin/lib/interpreter/*:' as a work-around.
 INFO [2020-01-12 12:15:50,035] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing view acls to: root
 INFO [2020-01-12 12:15:50,037] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing modify acls to: root
 INFO [2020-01-12 12:15:50,043] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing view acls groups to: 
 INFO [2020-01-12 12:15:50,045] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Changing modify acls groups to: 
 INFO [2020-01-12 12:15:50,048] ({pool-2-thread-2} Logging.scala[logInfo]:54) - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
 INFO [2020-01-12 12:15:50,816] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Successfully started service 'sparkDriver' on port 37527.
 INFO [2020-01-12 12:15:50,877] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering MapOutputTracker
 INFO [2020-01-12 12:15:50,941] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering BlockManagerMaster
 INFO [2020-01-12 12:15:50,948] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO [2020-01-12 12:15:50,950] ({pool-2-thread-2} Logging.scala[logInfo]:54) - BlockManagerMasterEndpoint up
 INFO [2020-01-12 12:15:50,981] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Created local directory at /tmp/blockmgr-7b951812-34f4-4f8a-bf68-7f006be77d5a
 INFO [2020-01-12 12:15:51,020] ({pool-2-thread-2} Logging.scala[logInfo]:54) - MemoryStore started with capacity 413.9 MB
 INFO [2020-01-12 12:15:51,166] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering OutputCommitCoordinator
 INFO [2020-01-12 12:15:51,699] ({pool-2-thread-2} Log.java[initialized]:186) - Logging initialized @27059ms
 INFO [2020-01-12 12:15:52,087] ({pool-2-thread-2} Server.java[doStart]:327) - jetty-9.2.z-SNAPSHOT
 INFO [2020-01-12 12:15:52,162] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@5e0fbc65{/jobs,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,169] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@9351ea2{/jobs/json,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,171] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@1a139c95{/jobs/job,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,172] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@6da6bdbb{/jobs/job/json,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,173] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@4ee9d8fe{/stages,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,175] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@6f081f8f{/stages/json,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,176] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@69f9d1cf{/stages/stage,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,179] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@316af22e{/stages/stage/json,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,185] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@3144e2d5{/stages/pool,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,186] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@1e9f6715{/stages/pool/json,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,187] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@394faaa0{/storage,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,189] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@5f52d425{/storage/json,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,190] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@4996d750{/storage/rdd,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,196] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@2c54b6b8{/storage/rdd/json,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,197] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@680a0338{/environment,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,198] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@21b001e0{/environment/json,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,199] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@5e637ed1{/executors,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,200] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@570bf2d3{/executors/json,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,201] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@6f2028c9{/executors/threadDump,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,211] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@4e3e9bcc{/executors/threadDump/json,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,231] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@b6ee12c{/static,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,232] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@3fb17f8{/,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,233] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@6df3112e{/api,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,234] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@572907a7{/jobs/job/kill,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,235] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@2b32ebef{/stages/stage/kill,null,AVAILABLE}
 INFO [2020-01-12 12:15:52,296] ({pool-2-thread-2} AbstractConnector.java[doStart]:266) - Started ServerConnector@60cbffe4{HTTP/1.1}{0.0.0.0:4040}
 INFO [2020-01-12 12:15:52,298] ({pool-2-thread-2} Server.java[doStart]:379) - Started @27657ms
 INFO [2020-01-12 12:15:52,298] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Successfully started service 'SparkUI' on port 4040.
 INFO [2020-01-12 12:15:52,301] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Bound SparkUI to 0.0.0.0, and started at http://172.18.0.2:4040
 INFO [2020-01-12 12:15:52,652] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Added file file:/zeppelin/interpreter/spark/pyspark/pyspark.zip at file:/zeppelin/interpreter/spark/pyspark/pyspark.zip with timestamp 1578831352651
 INFO [2020-01-12 12:15:52,673] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Copying /zeppelin/interpreter/spark/pyspark/pyspark.zip to /tmp/spark-65ace0ad-f3ed-4311-9fdf-b98378406c1f/userFiles-2b21868b-0a91-47bb-9518-9f15b6d52c51/pyspark.zip
 INFO [2020-01-12 12:15:52,782] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Added file file:/zeppelin/interpreter/spark/pyspark/py4j-0.10.4-src.zip at file:/zeppelin/interpreter/spark/pyspark/py4j-0.10.4-src.zip with timestamp 1578831352782
 INFO [2020-01-12 12:15:52,783] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Copying /zeppelin/interpreter/spark/pyspark/py4j-0.10.4-src.zip to /tmp/spark-65ace0ad-f3ed-4311-9fdf-b98378406c1f/userFiles-2b21868b-0a91-47bb-9518-9f15b6d52c51/py4j-0.10.4-src.zip
 INFO [2020-01-12 12:15:52,931] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Created default pool default, schedulingMode: FIFO, minShare: 0, weight: 1
 INFO [2020-01-12 12:15:53,003] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Starting executor ID driver on host localhost
 INFO [2020-01-12 12:15:53,026] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Using REPL class URI: spark://172.18.0.2:37527/classes
 INFO [2020-01-12 12:15:53,080] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34235.
 INFO [2020-01-12 12:15:53,081] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Server created on 172.18.0.2:34235
 INFO [2020-01-12 12:15:53,085] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO [2020-01-12 12:15:53,090] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registering BlockManager BlockManagerId(driver, 172.18.0.2, 34235, None)
 INFO [2020-01-12 12:15:53,096] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Registering block manager 172.18.0.2:34235 with 413.9 MB RAM, BlockManagerId(driver, 172.18.0.2, 34235, None)
 INFO [2020-01-12 12:15:53,113] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Registered BlockManager BlockManagerId(driver, 172.18.0.2, 34235, None)
 INFO [2020-01-12 12:15:53,114] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Initialized BlockManager: BlockManagerId(driver, 172.18.0.2, 34235, None)
 INFO [2020-01-12 12:15:53,628] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@fac8a27{/metrics/json,null,AVAILABLE}
 INFO [2020-01-12 12:15:53,733] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Warehouse path is 'file:/zeppelin/spark-warehouse'.
 INFO [2020-01-12 12:15:53,764] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@39b9ee9b{/SQL,null,AVAILABLE}
 INFO [2020-01-12 12:15:53,765] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@2ffdf0d9{/SQL/json,null,AVAILABLE}
 INFO [2020-01-12 12:15:53,768] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@2cfb301d{/SQL/execution,null,AVAILABLE}
 INFO [2020-01-12 12:15:53,773] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@6df04443{/SQL/execution/json,null,AVAILABLE}
 INFO [2020-01-12 12:15:53,776] ({pool-2-thread-2} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@dba1699{/static/sql,null,AVAILABLE}
 INFO [2020-01-12 12:15:53,932] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
 INFO [2020-01-12 12:15:56,864] ({pool-2-thread-2} HiveMetaStore.java[newRawStore]:589) - 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
 INFO [2020-01-12 12:15:56,964] ({pool-2-thread-2} ObjectStore.java[initialize]:289) - ObjectStore, initialize called
 INFO [2020-01-12 12:15:57,532] ({pool-2-thread-2} Log4JLogger.java[info]:77) - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
 INFO [2020-01-12 12:15:57,533] ({pool-2-thread-2} Log4JLogger.java[info]:77) - Property datanucleus.cache.level2 unknown - will be ignored
 INFO [2020-01-12 12:16:16,341] ({pool-2-thread-2} ObjectStore.java[getPMF]:370) - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
 INFO [2020-01-12 12:16:19,399] ({pool-2-thread-2} Log4JLogger.java[info]:77) - The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
 INFO [2020-01-12 12:16:19,405] ({pool-2-thread-2} Log4JLogger.java[info]:77) - The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
 INFO [2020-01-12 12:16:27,467] ({pool-2-thread-2} Log4JLogger.java[info]:77) - The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
 INFO [2020-01-12 12:16:27,468] ({pool-2-thread-2} Log4JLogger.java[info]:77) - The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
 INFO [2020-01-12 12:16:29,507] ({pool-2-thread-2} MetaStoreDirectSql.java[<init>]:139) - Using direct SQL, underlying DB is DERBY
 INFO [2020-01-12 12:16:29,564] ({pool-2-thread-2} ObjectStore.java[setConf]:272) - Initialized ObjectStore
 WARN [2020-01-12 12:16:30,483] ({pool-2-thread-2} ObjectStore.java[checkSchema]:6666) - Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
 WARN [2020-01-12 12:16:31,158] ({pool-2-thread-2} ObjectStore.java[getDatabase]:568) - Failed to get database default, returning NoSuchObjectException
 INFO [2020-01-12 12:16:31,905] ({pool-2-thread-2} HiveMetaStore.java[createDefaultRoles_core]:663) - Added admin role in metastore
 INFO [2020-01-12 12:16:31,934] ({pool-2-thread-2} HiveMetaStore.java[createDefaultRoles_core]:672) - Added public role in metastore
 INFO [2020-01-12 12:16:32,337] ({pool-2-thread-2} HiveMetaStore.java[addAdminUsers_core]:712) - No user is added in admin role, since config is empty
 INFO [2020-01-12 12:16:32,960] ({pool-2-thread-2} HiveMetaStore.java[logInfo]:746) - 0: get_all_databases
 INFO [2020-01-12 12:16:32,970] ({pool-2-thread-2} HiveMetaStore.java[logAuditEvent]:371) - ugi=root	ip=unknown-ip-addr	cmd=get_all_databases	
 INFO [2020-01-12 12:16:33,056] ({pool-2-thread-2} HiveMetaStore.java[logInfo]:746) - 0: get_functions: db=default pat=*
 INFO [2020-01-12 12:16:33,057] ({pool-2-thread-2} HiveMetaStore.java[logAuditEvent]:371) - ugi=root	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
 INFO [2020-01-12 12:16:33,060] ({pool-2-thread-2} Log4JLogger.java[info]:77) - The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
 INFO [2020-01-12 12:16:35,333] ({pool-2-thread-2} SessionState.java[createPath]:641) - Created HDFS directory: /tmp/hive/root
 INFO [2020-01-12 12:16:35,343] ({pool-2-thread-2} SessionState.java[createPath]:641) - Created local directory: /tmp/root
 INFO [2020-01-12 12:16:35,354] ({pool-2-thread-2} SessionState.java[createPath]:641) - Created local directory: /tmp/35d57d08-866f-45fc-aab9-178d3f1cb32d_resources
 INFO [2020-01-12 12:16:35,367] ({pool-2-thread-2} SessionState.java[createPath]:641) - Created HDFS directory: /tmp/hive/root/35d57d08-866f-45fc-aab9-178d3f1cb32d
 INFO [2020-01-12 12:16:35,382] ({pool-2-thread-2} SessionState.java[createPath]:641) - Created local directory: /tmp/root/35d57d08-866f-45fc-aab9-178d3f1cb32d
 INFO [2020-01-12 12:16:35,397] ({pool-2-thread-2} SessionState.java[createPath]:641) - Created HDFS directory: /tmp/hive/root/35d57d08-866f-45fc-aab9-178d3f1cb32d/_tmp_space.db
 INFO [2020-01-12 12:16:35,404] ({pool-2-thread-2} Logging.scala[logInfo]:54) - Warehouse location for Hive client (version 1.2.1) is file:/zeppelin/spark-warehouse
 INFO [2020-01-12 12:16:35,436] ({pool-2-thread-2} HiveMetaStore.java[logInfo]:746) - 0: get_database: default
 INFO [2020-01-12 12:16:35,440] ({pool-2-thread-2} HiveMetaStore.java[logAuditEvent]:371) - ugi=root	ip=unknown-ip-addr	cmd=get_database: default	
 INFO [2020-01-12 12:16:35,519] ({pool-2-thread-2} HiveMetaStore.java[logInfo]:746) - 0: get_database: global_temp
 INFO [2020-01-12 12:16:35,520] ({pool-2-thread-2} HiveMetaStore.java[logAuditEvent]:371) - ugi=root	ip=unknown-ip-addr	cmd=get_database: global_temp	
 WARN [2020-01-12 12:16:35,522] ({pool-2-thread-2} ObjectStore.java[getDatabase]:568) - Failed to get database global_temp, returning NoSuchObjectException
 INFO [2020-01-12 12:16:35,550] ({pool-2-thread-2} SparkInterpreter.java[createSparkSession]:362) - Created Spark session with Hive support
 INFO [2020-01-12 12:16:52,851] ({pool-2-thread-2} SparkInterpreter.java[populateSparkWebUrl]:997) - Sending metainfos to Zeppelin server: {url=http://172.18.0.2:4040}
 INFO [2020-01-12 12:16:52,922] ({pool-2-thread-2} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578831327784 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter2057123742
 INFO [2020-01-12 12:18:15,872] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578831495850 started by scheduler org.apache.zeppelin.spark.SparkInterpreter2057123742
 INFO [2020-01-12 12:18:15,901] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578831495850 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter2057123742
 INFO [2020-01-12 12:18:42,115] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578831522114 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:18:42,155] ({pool-2-thread-5} PySparkInterpreter.java[createPythonScript]:108) - File /tmp/zeppelin_pyspark-6371845956874192597.py created
 INFO [2020-01-12 12:18:49,149] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578831522114 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:19:06,983] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578831546982 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:19:06,993] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578831546982 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:19:40,303] ({pool-2-thread-6} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578831580302 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:19:40,364] ({pool-2-thread-6} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578831580302 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:22:12,833] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578831732821 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:22:12,853] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578831732821 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:24:55,314] ({pool-2-thread-7} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578831895311 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:24:55,346] ({pool-2-thread-7} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578831895311 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:24:55,751] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578831895750 started by scheduler org.apache.zeppelin.spark.SparkInterpreter2057123742
 INFO [2020-01-12 12:24:56,879] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578831895750 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter2057123742
 INFO [2020-01-12 12:25:08,552] ({pool-2-thread-12} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578831908550 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:25:08,580] ({pool-2-thread-12} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578831908550 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:25:09,222] ({pool-2-thread-6} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578831909222 started by scheduler org.apache.zeppelin.spark.SparkInterpreter2057123742
 INFO [2020-01-12 12:25:09,254] ({pool-2-thread-6} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578831909222 finished by scheduler org.apache.zeppelin.spark.SparkInterpreter2057123742
 INFO [2020-01-12 12:25:29,239] ({pool-2-thread-9} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578831929238 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:25:29,279] ({pool-2-thread-9} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578831929238 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:25:52,516] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578831952513 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:25:52,545] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578831952513 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:26:01,494] ({pool-2-thread-10} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578831961493 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:26:01,890] ({pool-2-thread-10} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578831961493 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:27:26,608] ({pool-2-thread-7} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578832046607 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:27:26,632] ({pool-2-thread-7} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578832046607 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:27:34,175] ({pool-2-thread-11} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578832054173 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:27:34,214] ({pool-2-thread-11} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578832054173 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:27:54,036] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578832074036 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:27:54,131] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578832074036 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:28:48,860] ({pool-2-thread-8} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578832128860 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:28:48,909] ({pool-2-thread-8} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578832128860 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:29:56,772] ({pool-2-thread-12} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578832196771 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:29:56,808] ({pool-2-thread-12} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578832196771 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:30:27,982] ({pool-2-thread-13} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578832227975 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:30:28,009] ({pool-2-thread-13} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578832227975 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:33:21,542] ({pool-2-thread-6} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578832401540 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:33:21,658] ({pool-2-thread-6} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578832401540 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:34:32,408] ({pool-2-thread-14} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578832472377 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:34:32,439] ({pool-2-thread-14} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578832472377 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:34:55,406] ({pool-2-thread-9} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578832495406 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:34:57,052] ({pool-2-thread-9} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578832495406 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:36:29,500] ({pool-2-thread-15} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578832589492 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:36:29,530] ({pool-2-thread-15} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578832589492 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:36:54,313] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578832614311 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:36:54,343] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578832614311 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:36:59,792] ({pool-2-thread-16} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578832619791 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:37:00,797] ({pool-2-thread-16} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578832619791 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:38:23,619] ({pool-2-thread-10} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578832703618 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:38:40,217] ({pool-2-thread-10} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578832703618 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:39:00,947] ({pool-2-thread-17} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578832740945 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:39:01,467] ({pool-2-thread-17} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578832740945 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:39:12,395] ({pool-2-thread-7} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578832752373 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:39:27,871] ({pool-2-thread-7} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578832752373 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:40:32,413] ({pool-2-thread-18} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578832832411 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:40:48,058] ({pool-2-thread-18} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578832832411 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:45:41,936] ({pool-2-thread-11} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578833141932 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:46:58,918] ({pool-2-thread-11} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578833141932 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:50:37,604] ({pool-2-thread-19} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578833437558 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:50:39,410] ({pool-2-thread-19} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578833437558 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:52:22,140] ({pool-2-thread-35} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578833542139 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:52:22,949] ({Thread-32} Logging.scala[logInfo]:54) - Starting job: collect at <stdin>:11
 INFO [2020-01-12 12:52:23,043] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 0 (collect at <stdin>:11) with 4 output partitions
 INFO [2020-01-12 12:52:23,046] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 0 (collect at <stdin>:11)
 INFO [2020-01-12 12:52:23,048] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 12:52:23,056] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 12:52:23,111] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 0 (CartesianRDD[2] at cartesian at NativeMethodAccessorImpl.java:0), which has no missing parents
 INFO [2020-01-12 12:52:23,486] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_0 stored as values in memory (estimated size 1816.0 B, free 413.9 MB)
 INFO [2020-01-12 12:52:23,649] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1141.0 B, free 413.9 MB)
 INFO [2020-01-12 12:52:23,661] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Added broadcast_0_piece0 in memory on 172.18.0.2:34235 (size: 1141.0 B, free: 413.9 MB)
 INFO [2020-01-12 12:52:23,686] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 12:52:23,736] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 4 missing tasks from ResultStage 0 (CartesianRDD[2] at cartesian at NativeMethodAccessorImpl.java:0)
 INFO [2020-01-12 12:52:23,742] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 0.0 with 4 tasks
 INFO [2020-01-12 12:52:23,796] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_0.0 tasks to pool default
 INFO [2020-01-12 12:52:24,078] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7391 bytes)
 INFO [2020-01-12 12:52:24,113] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 8367 bytes)
 INFO [2020-01-12 12:52:24,142] ({Executor task launch worker-0} Logging.scala[logInfo]:54) - Running task 0.0 in stage 0.0 (TID 0)
 INFO [2020-01-12 12:52:24,143] ({Executor task launch worker-1} Logging.scala[logInfo]:54) - Running task 1.0 in stage 0.0 (TID 1)
 INFO [2020-01-12 12:52:24,163] ({Executor task launch worker-0} Logging.scala[logInfo]:54) - Fetching file:/zeppelin/interpreter/spark/pyspark/py4j-0.10.4-src.zip with timestamp 1578831352782
 INFO [2020-01-12 12:52:24,415] ({Executor task launch worker-0} Logging.scala[logInfo]:54) - /zeppelin/interpreter/spark/pyspark/py4j-0.10.4-src.zip has been previously copied to /tmp/spark-65ace0ad-f3ed-4311-9fdf-b98378406c1f/userFiles-2b21868b-0a91-47bb-9518-9f15b6d52c51/py4j-0.10.4-src.zip
 INFO [2020-01-12 12:52:24,670] ({Executor task launch worker-0} Logging.scala[logInfo]:54) - Fetching file:/zeppelin/interpreter/spark/pyspark/pyspark.zip with timestamp 1578831352651
 INFO [2020-01-12 12:52:24,695] ({Executor task launch worker-0} Logging.scala[logInfo]:54) - /zeppelin/interpreter/spark/pyspark/pyspark.zip has been previously copied to /tmp/spark-65ace0ad-f3ed-4311-9fdf-b98378406c1f/userFiles-2b21868b-0a91-47bb-9518-9f15b6d52c51/pyspark.zip
 INFO [2020-01-12 12:52:24,992] ({Executor task launch worker-0} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 0.0 (TID 0). 1953 bytes result sent to driver
 INFO [2020-01-12 12:52:24,993] ({Executor task launch worker-1} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 0.0 (TID 1). 2982 bytes result sent to driver
 INFO [2020-01-12 12:52:25,003] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8367 bytes)
 INFO [2020-01-12 12:52:25,011] ({Executor task launch worker-1} Logging.scala[logInfo]:54) - Running task 2.0 in stage 0.0 (TID 2)
 INFO [2020-01-12 12:52:25,015] ({Executor task launch worker-1} Logging.scala[logInfo]:54) - Finished task 2.0 in stage 0.0 (TID 2). 2895 bytes result sent to driver
 INFO [2020-01-12 12:52:25,026] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 7391 bytes)
 INFO [2020-01-12 12:52:25,030] ({Executor task launch worker-1} Logging.scala[logInfo]:54) - Running task 3.0 in stage 0.0 (TID 3)
 INFO [2020-01-12 12:52:25,046] ({Executor task launch worker-1} Logging.scala[logInfo]:54) - Finished task 3.0 in stage 0.0 (TID 3). 1953 bytes result sent to driver
 INFO [2020-01-12 12:52:25,161] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 2.0 in stage 0.0 (TID 2) in 66 ms on localhost (executor driver) (1/4)
 INFO [2020-01-12 12:52:25,161] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 0.0 (TID 1) in 1059 ms on localhost (executor driver) (2/4)
 INFO [2020-01-12 12:52:25,162] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 3.0 in stage 0.0 (TID 3) in 138 ms on localhost (executor driver) (3/4)
 INFO [2020-01-12 12:52:25,163] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 0.0 (TID 0) in 1268 ms on localhost (executor driver) (4/4)
 INFO [2020-01-12 12:52:25,167] ({task-result-getter-0} Logging.scala[logInfo]:54) - Removed TaskSet 0.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 12:52:25,193] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 0 (collect at <stdin>:11) finished in 1.369 s
 INFO [2020-01-12 12:52:25,258] ({Thread-32} Logging.scala[logInfo]:54) - Job 0 finished: collect at <stdin>:11, took 2.306313 s
 INFO [2020-01-12 12:52:25,451] ({pool-2-thread-35} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578833542139 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:53:21,458] ({pool-2-thread-20} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578833601449 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:53:21,585] ({Thread-32} Logging.scala[logInfo]:54) - Starting job: collect at <stdin>:11
 INFO [2020-01-12 12:53:21,591] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 1 (collect at <stdin>:11) with 4 output partitions
 INFO [2020-01-12 12:53:21,592] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 1 (collect at <stdin>:11)
 INFO [2020-01-12 12:53:21,592] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 12:53:21,592] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 12:53:21,593] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 1 (CartesianRDD[4] at cartesian at NativeMethodAccessorImpl.java:0), which has no missing parents
 INFO [2020-01-12 12:53:21,599] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_1 stored as values in memory (estimated size 1816.0 B, free 413.9 MB)
 INFO [2020-01-12 12:53:21,639] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_1_piece0 stored as bytes in memory (estimated size 1142.0 B, free 413.9 MB)
 INFO [2020-01-12 12:53:21,640] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Added broadcast_1_piece0 in memory on 172.18.0.2:34235 (size: 1142.0 B, free: 413.9 MB)
 INFO [2020-01-12 12:53:21,647] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 1 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 12:53:21,648] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 4 missing tasks from ResultStage 1 (CartesianRDD[4] at cartesian at NativeMethodAccessorImpl.java:0)
 INFO [2020-01-12 12:53:21,648] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 1.0 with 4 tasks
 INFO [2020-01-12 12:53:21,650] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_1.0 tasks to pool default
 INFO [2020-01-12 12:53:21,656] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7391 bytes)
 INFO [2020-01-12 12:53:21,658] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 8367 bytes)
 INFO [2020-01-12 12:53:21,659] ({Executor task launch worker-0} Logging.scala[logInfo]:54) - Running task 1.0 in stage 1.0 (TID 5)
 INFO [2020-01-12 12:53:21,668] ({Executor task launch worker-1} Logging.scala[logInfo]:54) - Running task 0.0 in stage 1.0 (TID 4)
 INFO [2020-01-12 12:53:21,676] ({Executor task launch worker-1} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 1.0 (TID 4). 1953 bytes result sent to driver
 INFO [2020-01-12 12:53:21,678] ({Executor task launch worker-0} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 1.0 (TID 5). 2895 bytes result sent to driver
 INFO [2020-01-12 12:53:21,688] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 2.0 in stage 1.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 8367 bytes)
 INFO [2020-01-12 12:53:21,692] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 1.0 (TID 4) in 39 ms on localhost (executor driver) (1/4)
 INFO [2020-01-12 12:53:21,698] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 3.0 in stage 1.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 7391 bytes)
 INFO [2020-01-12 12:53:21,703] ({Executor task launch worker-0} Logging.scala[logInfo]:54) - Running task 2.0 in stage 1.0 (TID 6)
 INFO [2020-01-12 12:53:21,705] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 1.0 (TID 5) in 48 ms on localhost (executor driver) (2/4)
 INFO [2020-01-12 12:53:21,705] ({Executor task launch worker-1} Logging.scala[logInfo]:54) - Running task 3.0 in stage 1.0 (TID 7)
 INFO [2020-01-12 12:53:21,761] ({Executor task launch worker-1} Logging.scala[logInfo]:54) - Finished task 3.0 in stage 1.0 (TID 7). 1953 bytes result sent to driver
 INFO [2020-01-12 12:53:21,768] ({Executor task launch worker-0} Logging.scala[logInfo]:54) - Finished task 2.0 in stage 1.0 (TID 6). 2982 bytes result sent to driver
 INFO [2020-01-12 12:53:21,779] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 3.0 in stage 1.0 (TID 7) in 83 ms on localhost (executor driver) (3/4)
 INFO [2020-01-12 12:53:21,783] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 2.0 in stage 1.0 (TID 6) in 98 ms on localhost (executor driver) (4/4)
 INFO [2020-01-12 12:53:21,783] ({task-result-getter-0} Logging.scala[logInfo]:54) - Removed TaskSet 1.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 12:53:21,785] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 1 (collect at <stdin>:11) finished in 0.134 s
 INFO [2020-01-12 12:53:21,786] ({Thread-32} Logging.scala[logInfo]:54) - Job 1 finished: collect at <stdin>:11, took 0.200888 s
 INFO [2020-01-12 12:53:21,842] ({pool-2-thread-20} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578833601449 finished by scheduler interpreter_627332391
 INFO [2020-01-12 12:53:22,798] ({pool-1-thread-2} RemoteInterpreterServer.java[cancel]:538) - cancel org.apache.zeppelin.spark.PySparkInterpreter 20200111-161244_906731520
 INFO [2020-01-12 12:53:22,802] ({pool-1-thread-2} Logging.scala[logInfo]:54) - Asked to cancel job group zeppelin-20200111-161244_906731520
 INFO [2020-01-12 12:53:22,802] ({pool-1-thread-2} PySparkInterpreter.java[interrupt]:419) - Sending SIGINT signal to PID : 167
 INFO [2020-01-12 12:56:07,625] ({pool-2-thread-8} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578833767620 started by scheduler interpreter_627332391
 INFO [2020-01-12 12:59:58,675] ({pool-1-thread-5} RemoteInterpreterServer.java[cancel]:538) - cancel org.apache.zeppelin.spark.PySparkInterpreter 20200111-161244_906731520
 INFO [2020-01-12 12:59:58,675] ({pool-1-thread-5} Logging.scala[logInfo]:54) - Asked to cancel job group zeppelin-20200111-161244_906731520
 INFO [2020-01-12 12:59:58,676] ({pool-1-thread-5} PySparkInterpreter.java[interrupt]:419) - Sending SIGINT signal to PID : 167
 INFO [2020-01-12 13:00:04,375] ({pool-1-thread-5} RemoteInterpreterServer.java[cancel]:538) - cancel org.apache.zeppelin.spark.PySparkInterpreter 20200111-161244_906731520
 INFO [2020-01-12 13:00:04,376] ({pool-1-thread-5} Logging.scala[logInfo]:54) - Asked to cancel job group zeppelin-20200111-161244_906731520
 INFO [2020-01-12 13:00:04,376] ({pool-1-thread-5} PySparkInterpreter.java[interrupt]:419) - Sending SIGINT signal to PID : 167
 INFO [2020-01-12 13:00:34,383] ({pool-1-thread-4} RemoteInterpreterServer.java[cancel]:538) - cancel org.apache.zeppelin.spark.PySparkInterpreter 20200111-161244_906731520
 INFO [2020-01-12 13:00:34,389] ({pool-1-thread-4} Logging.scala[logInfo]:54) - Asked to cancel job group zeppelin-20200111-161244_906731520
 INFO [2020-01-12 13:00:34,389] ({pool-1-thread-4} PySparkInterpreter.java[interrupt]:419) - Sending SIGINT signal to PID : 167
 INFO [2020-01-12 13:01:29,026] ({pool-1-thread-4} RemoteInterpreterServer.java[cancel]:538) - cancel org.apache.zeppelin.spark.PySparkInterpreter 20200111-161244_906731520
 INFO [2020-01-12 13:01:29,027] ({pool-1-thread-4} Logging.scala[logInfo]:54) - Asked to cancel job group zeppelin-20200111-161244_906731520
 INFO [2020-01-12 13:01:29,027] ({pool-1-thread-4} PySparkInterpreter.java[interrupt]:419) - Sending SIGINT signal to PID : 167
 INFO [2020-01-12 13:04:27,734] ({pool-1-thread-4} RemoteInterpreterServer.java[cancel]:538) - cancel org.apache.zeppelin.spark.PySparkInterpreter 20200111-161244_906731520
 INFO [2020-01-12 13:04:27,736] ({pool-1-thread-4} Logging.scala[logInfo]:54) - Asked to cancel job group zeppelin-20200111-161244_906731520
 INFO [2020-01-12 13:04:27,737] ({pool-1-thread-4} PySparkInterpreter.java[interrupt]:419) - Sending SIGINT signal to PID : 167
 INFO [2020-01-12 13:04:27,752] ({pool-1-thread-4} RemoteInterpreterServer.java[cancel]:538) - cancel org.apache.zeppelin.spark.SparkInterpreter 20200112-122455_749738633
 INFO [2020-01-12 13:04:27,754] ({pool-1-thread-4} Logging.scala[logInfo]:54) - Asked to cancel job group zeppelin-20200112-122455_749738633
 INFO [2020-01-12 13:05:10,975] ({pool-1-thread-4} InterpreterGroup.java[close]:151) - Close interpreter group 2F12443YN:shared_process
 INFO [2020-01-12 13:05:10,987] ({Thread-67} SparkInterpreter.java[close]:1385) - Close interpreter
 INFO [2020-01-12 13:05:11,175] ({Thread-67} AbstractConnector.java[doStop]:306) - Stopped ServerConnector@60cbffe4{HTTP/1.1}{0.0.0.0:4040}
 INFO [2020-01-12 13:05:11,206] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@2b32ebef{/stages/stage/kill,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,208] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@572907a7{/jobs/job/kill,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,209] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@6df3112e{/api,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,210] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@3fb17f8{/,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,213] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@b6ee12c{/static,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,214] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@4e3e9bcc{/executors/threadDump/json,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,215] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@6f2028c9{/executors/threadDump,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,215] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@570bf2d3{/executors/json,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,216] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@5e637ed1{/executors,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,216] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@21b001e0{/environment/json,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,217] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@680a0338{/environment,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,218] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@2c54b6b8{/storage/rdd/json,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,218] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@4996d750{/storage/rdd,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,219] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@5f52d425{/storage/json,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,219] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@394faaa0{/storage,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,220] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@1e9f6715{/stages/pool/json,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,221] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@3144e2d5{/stages/pool,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,221] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@316af22e{/stages/stage/json,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,222] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@69f9d1cf{/stages/stage,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,222] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@6f081f8f{/stages/json,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,223] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@4ee9d8fe{/stages,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,224] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@6da6bdbb{/jobs/job/json,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,224] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@1a139c95{/jobs/job,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,225] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@9351ea2{/jobs/json,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,226] ({Thread-67} ContextHandler.java[doStop]:865) - Stopped o.s.j.s.ServletContextHandler@5e0fbc65{/jobs,null,UNAVAILABLE}
 INFO [2020-01-12 13:05:11,242] ({Thread-67} Logging.scala[logInfo]:54) - Stopped Spark web UI at http://172.18.0.2:4040
 INFO [2020-01-12 13:05:11,326] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - MapOutputTrackerMasterEndpoint stopped!
 INFO [2020-01-12 13:05:11,428] ({Thread-67} Logging.scala[logInfo]:54) - MemoryStore cleared
 INFO [2020-01-12 13:05:11,432] ({Thread-67} Logging.scala[logInfo]:54) - BlockManager stopped
 INFO [2020-01-12 13:05:11,434] ({Thread-67} Logging.scala[logInfo]:54) - BlockManagerMaster stopped
 INFO [2020-01-12 13:05:11,455] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - OutputCommitCoordinator stopped!
 INFO [2020-01-12 13:05:11,463] ({Thread-67} Logging.scala[logInfo]:54) - Successfully stopped SparkContext
 INFO [2020-01-12 13:05:13,606] ({Thread-3} Logging.scala[logInfo]:54) - Shutdown hook called
 INFO [2020-01-12 13:05:13,610] ({Thread-3} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-88e050d4-2b89-4a54-bbaa-7c43098e347b
 INFO [2020-01-12 13:05:13,654] ({Thread-3} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-65ace0ad-f3ed-4311-9fdf-b98378406c1f
 INFO [2020-01-12 13:05:13,655] ({Thread-3} Logging.scala[logInfo]:54) - Deleting directory /tmp/spark-65ace0ad-f3ed-4311-9fdf-b98378406c1f/pyspark-0a81c1aa-ded7-492e-92f8-cd1532cadef3
 INFO [2020-01-12 13:05:34,350] ({Thread-0} RemoteInterpreterServer.java[run]:97) - Starting remote interpreter server on port 37517
 INFO [2020-01-12 13:05:35,735] ({pool-1-thread-2} RemoteInterpreterServer.java[createInterpreter]:198) - Instantiate interpreter org.apache.zeppelin.spark.SparkInterpreter
 INFO [2020-01-12 13:05:35,804] ({pool-1-thread-2} RemoteInterpreterServer.java[createInterpreter]:198) - Instantiate interpreter org.apache.zeppelin.spark.SparkSqlInterpreter
 INFO [2020-01-12 13:05:35,831] ({pool-1-thread-2} RemoteInterpreterServer.java[createInterpreter]:198) - Instantiate interpreter org.apache.zeppelin.spark.DepInterpreter
 INFO [2020-01-12 13:05:35,888] ({pool-1-thread-2} RemoteInterpreterServer.java[createInterpreter]:198) - Instantiate interpreter org.apache.zeppelin.spark.PySparkInterpreter
 INFO [2020-01-12 13:05:35,893] ({pool-1-thread-2} RemoteInterpreterServer.java[createInterpreter]:198) - Instantiate interpreter org.apache.zeppelin.spark.SparkRInterpreter
 INFO [2020-01-12 13:05:35,982] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578834335977 started by scheduler interpreter_1602312349
 INFO [2020-01-12 13:05:35,998] ({pool-2-thread-4} PySparkInterpreter.java[createPythonScript]:108) - File /tmp/zeppelin_pyspark-3035509077474122588.py created
 INFO [2020-01-12 13:05:43,818] ({pool-2-thread-4} SparkInterpreter.java[createSparkSession]:318) - ------ Create new SparkContext local[*] -------
 WARN [2020-01-12 13:05:43,833] ({pool-2-thread-4} SparkInterpreter.java[setupConfForSparkR]:562) - sparkr.zip is not found, sparkr may not work.
 INFO [2020-01-12 13:05:45,056] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Running Spark version 2.1.0
 WARN [2020-01-12 13:05:45,896] ({pool-2-thread-4} NativeCodeLoader.java[<clinit>]:62) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
 WARN [2020-01-12 13:05:46,102] ({pool-2-thread-4} Logging.scala[logWarning]:66) - 
SPARK_CLASSPATH was detected (set to ':/zeppelin/interpreter/spark/dep/*:/zeppelin/interpreter/spark/*:/zeppelin/lib/interpreter/*:').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with --driver-class-path to augment the driver classpath
 - spark.executor.extraClassPath to augment the executor classpath
        
 WARN [2020-01-12 13:05:46,107] ({pool-2-thread-4} Logging.scala[logWarning]:66) - Setting 'spark.executor.extraClassPath' to ':/zeppelin/interpreter/spark/dep/*:/zeppelin/interpreter/spark/*:/zeppelin/lib/interpreter/*:' as a work-around.
 WARN [2020-01-12 13:05:46,109] ({pool-2-thread-4} Logging.scala[logWarning]:66) - Setting 'spark.driver.extraClassPath' to ':/zeppelin/interpreter/spark/dep/*:/zeppelin/interpreter/spark/*:/zeppelin/lib/interpreter/*:' as a work-around.
 INFO [2020-01-12 13:05:46,197] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Changing view acls to: root
 INFO [2020-01-12 13:05:46,201] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Changing modify acls to: root
 INFO [2020-01-12 13:05:46,205] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Changing view acls groups to: 
 INFO [2020-01-12 13:05:46,209] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Changing modify acls groups to: 
 INFO [2020-01-12 13:05:46,211] ({pool-2-thread-4} Logging.scala[logInfo]:54) - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
 INFO [2020-01-12 13:05:46,980] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Successfully started service 'sparkDriver' on port 43101.
 INFO [2020-01-12 13:05:47,046] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Registering MapOutputTracker
 INFO [2020-01-12 13:05:47,110] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Registering BlockManagerMaster
 INFO [2020-01-12 13:05:47,120] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
 INFO [2020-01-12 13:05:47,123] ({pool-2-thread-4} Logging.scala[logInfo]:54) - BlockManagerMasterEndpoint up
 INFO [2020-01-12 13:05:47,157] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Created local directory at /tmp/blockmgr-ba2fa50f-7493-45db-835e-eb90d7245570
 INFO [2020-01-12 13:05:47,211] ({pool-2-thread-4} Logging.scala[logInfo]:54) - MemoryStore started with capacity 413.9 MB
 INFO [2020-01-12 13:05:47,392] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Registering OutputCommitCoordinator
 INFO [2020-01-12 13:05:47,674] ({pool-2-thread-4} Log.java[initialized]:186) - Logging initialized @15728ms
 INFO [2020-01-12 13:05:47,974] ({pool-2-thread-4} Server.java[doStart]:327) - jetty-9.2.z-SNAPSHOT
 INFO [2020-01-12 13:05:48,030] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@e60e68e{/jobs,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,031] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@254095e0{/jobs/json,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,032] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@dd4a68f{/jobs/job,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,033] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@2f209c10{/jobs/job/json,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,034] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@267d5bec{/stages,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,035] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@7332556{/stages/json,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,035] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@2ffb0be1{/stages/stage,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,040] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@410c212{/stages/stage/json,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,082] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@487e4b47{/stages/pool,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,083] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@5679ce8b{/stages/pool/json,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,083] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@21aa63a6{/storage,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,084] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@23a835d3{/storage/json,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,085] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@19366692{/storage/rdd,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,086] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@1a3eea9{/storage/rdd/json,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,087] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@73660a68{/environment,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,088] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@1102af7a{/environment/json,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,089] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@3b2a593e{/executors,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,091] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@25e22e54{/executors/json,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,109] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@669455ca{/executors/threadDump,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,110] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@62e95f1d{/executors/threadDump/json,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,127] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@b6319d7{/static,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,128] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@3fc70661{/,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,129] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@7b393e56{/api,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,130] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@5300879b{/jobs/job/kill,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,131] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@40be918d{/stages/stage/kill,null,AVAILABLE}
 INFO [2020-01-12 13:05:48,161] ({pool-2-thread-4} AbstractConnector.java[doStart]:266) - Started ServerConnector@3a0862ed{HTTP/1.1}{0.0.0.0:4040}
 INFO [2020-01-12 13:05:48,164] ({pool-2-thread-4} Server.java[doStart]:379) - Started @16218ms
 INFO [2020-01-12 13:05:48,164] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Successfully started service 'SparkUI' on port 4040.
 INFO [2020-01-12 13:05:48,172] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Bound SparkUI to 0.0.0.0, and started at http://172.18.0.2:4040
 INFO [2020-01-12 13:05:48,494] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Added file file:/zeppelin/interpreter/spark/pyspark/pyspark.zip at file:/zeppelin/interpreter/spark/pyspark/pyspark.zip with timestamp 1578834348493
 INFO [2020-01-12 13:05:48,500] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Copying /zeppelin/interpreter/spark/pyspark/pyspark.zip to /tmp/spark-3fe95cff-4c85-44b1-b78b-d9d51834d0b0/userFiles-dec7a40c-cbbe-47c0-934e-52f79ec6064b/pyspark.zip
 INFO [2020-01-12 13:05:48,567] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Added file file:/zeppelin/interpreter/spark/pyspark/py4j-0.10.4-src.zip at file:/zeppelin/interpreter/spark/pyspark/py4j-0.10.4-src.zip with timestamp 1578834348567
 INFO [2020-01-12 13:05:48,568] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Copying /zeppelin/interpreter/spark/pyspark/py4j-0.10.4-src.zip to /tmp/spark-3fe95cff-4c85-44b1-b78b-d9d51834d0b0/userFiles-dec7a40c-cbbe-47c0-934e-52f79ec6064b/py4j-0.10.4-src.zip
 INFO [2020-01-12 13:05:48,721] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Created default pool default, schedulingMode: FIFO, minShare: 0, weight: 1
 INFO [2020-01-12 13:05:48,781] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Starting executor ID driver on host localhost
 INFO [2020-01-12 13:05:48,801] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Using REPL class URI: spark://172.18.0.2:43101/classes
 INFO [2020-01-12 13:05:48,860] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34393.
 INFO [2020-01-12 13:05:48,861] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Server created on 172.18.0.2:34393
 INFO [2020-01-12 13:05:48,866] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
 INFO [2020-01-12 13:05:48,870] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Registering BlockManager BlockManagerId(driver, 172.18.0.2, 34393, None)
 INFO [2020-01-12 13:05:48,879] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Registering block manager 172.18.0.2:34393 with 413.9 MB RAM, BlockManagerId(driver, 172.18.0.2, 34393, None)
 INFO [2020-01-12 13:05:48,891] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Registered BlockManager BlockManagerId(driver, 172.18.0.2, 34393, None)
 INFO [2020-01-12 13:05:48,892] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Initialized BlockManager: BlockManagerId(driver, 172.18.0.2, 34393, None)
 INFO [2020-01-12 13:05:49,416] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@6dca5f94{/metrics/json,null,AVAILABLE}
 INFO [2020-01-12 13:05:49,566] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Warehouse path is 'file:/zeppelin/spark-warehouse'.
 INFO [2020-01-12 13:05:49,596] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@30dea6f7{/SQL,null,AVAILABLE}
 INFO [2020-01-12 13:05:49,597] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@52986be6{/SQL/json,null,AVAILABLE}
 INFO [2020-01-12 13:05:49,599] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@3cfea4d9{/SQL/execution,null,AVAILABLE}
 INFO [2020-01-12 13:05:49,600] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@308ef091{/SQL/execution/json,null,AVAILABLE}
 INFO [2020-01-12 13:05:49,607] ({pool-2-thread-4} ContextHandler.java[doStart]:744) - Started o.s.j.s.ServletContextHandler@36e64ed5{/static/sql,null,AVAILABLE}
 INFO [2020-01-12 13:05:49,793] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
 INFO [2020-01-12 13:05:52,469] ({pool-2-thread-4} HiveMetaStore.java[newRawStore]:589) - 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
 INFO [2020-01-12 13:05:52,615] ({pool-2-thread-4} ObjectStore.java[initialize]:289) - ObjectStore, initialize called
 INFO [2020-01-12 13:05:53,077] ({pool-2-thread-4} Log4JLogger.java[info]:77) - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
 INFO [2020-01-12 13:05:53,078] ({pool-2-thread-4} Log4JLogger.java[info]:77) - Property datanucleus.cache.level2 unknown - will be ignored
 INFO [2020-01-12 13:06:01,591] ({pool-2-thread-4} ObjectStore.java[getPMF]:370) - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
 INFO [2020-01-12 13:06:07,088] ({pool-2-thread-4} Log4JLogger.java[info]:77) - The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
 INFO [2020-01-12 13:06:07,091] ({pool-2-thread-4} Log4JLogger.java[info]:77) - The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
 INFO [2020-01-12 13:06:07,765] ({pool-2-thread-4} Log4JLogger.java[info]:77) - The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
 INFO [2020-01-12 13:06:07,767] ({pool-2-thread-4} Log4JLogger.java[info]:77) - The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
 INFO [2020-01-12 13:06:08,012] ({pool-2-thread-4} Log4JLogger.java[info]:77) - Reading in results for query "org.datanucleus.store.rdbms.query.SQLQuery@0" since the connection used is closing
 INFO [2020-01-12 13:06:08,017] ({pool-2-thread-4} MetaStoreDirectSql.java[<init>]:139) - Using direct SQL, underlying DB is DERBY
 INFO [2020-01-12 13:06:08,029] ({pool-2-thread-4} ObjectStore.java[setConf]:272) - Initialized ObjectStore
 INFO [2020-01-12 13:06:08,986] ({pool-2-thread-4} HiveMetaStore.java[createDefaultRoles_core]:663) - Added admin role in metastore
 INFO [2020-01-12 13:06:08,992] ({pool-2-thread-4} HiveMetaStore.java[createDefaultRoles_core]:672) - Added public role in metastore
 INFO [2020-01-12 13:06:09,097] ({pool-2-thread-4} HiveMetaStore.java[addAdminUsers_core]:712) - No user is added in admin role, since config is empty
 INFO [2020-01-12 13:06:09,495] ({pool-2-thread-4} HiveMetaStore.java[logInfo]:746) - 0: get_all_databases
 INFO [2020-01-12 13:06:09,501] ({pool-2-thread-4} HiveMetaStore.java[logAuditEvent]:371) - ugi=root	ip=unknown-ip-addr	cmd=get_all_databases	
 INFO [2020-01-12 13:06:09,595] ({pool-2-thread-4} HiveMetaStore.java[logInfo]:746) - 0: get_functions: db=default pat=*
 INFO [2020-01-12 13:06:09,596] ({pool-2-thread-4} HiveMetaStore.java[logAuditEvent]:371) - ugi=root	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
 INFO [2020-01-12 13:06:09,604] ({pool-2-thread-4} Log4JLogger.java[info]:77) - The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
 INFO [2020-01-12 13:06:10,528] ({pool-2-thread-4} SessionState.java[createPath]:641) - Created local directory: /tmp/6000c431-2d3a-4713-a3ce-b8e5d477c10c_resources
 INFO [2020-01-12 13:06:10,542] ({pool-2-thread-4} SessionState.java[createPath]:641) - Created HDFS directory: /tmp/hive/root/6000c431-2d3a-4713-a3ce-b8e5d477c10c
 INFO [2020-01-12 13:06:10,551] ({pool-2-thread-4} SessionState.java[createPath]:641) - Created local directory: /tmp/root/6000c431-2d3a-4713-a3ce-b8e5d477c10c
 INFO [2020-01-12 13:06:10,566] ({pool-2-thread-4} SessionState.java[createPath]:641) - Created HDFS directory: /tmp/hive/root/6000c431-2d3a-4713-a3ce-b8e5d477c10c/_tmp_space.db
 INFO [2020-01-12 13:06:10,575] ({pool-2-thread-4} Logging.scala[logInfo]:54) - Warehouse location for Hive client (version 1.2.1) is file:/zeppelin/spark-warehouse
 INFO [2020-01-12 13:06:10,630] ({pool-2-thread-4} HiveMetaStore.java[logInfo]:746) - 0: get_database: default
 INFO [2020-01-12 13:06:10,631] ({pool-2-thread-4} HiveMetaStore.java[logAuditEvent]:371) - ugi=root	ip=unknown-ip-addr	cmd=get_database: default	
 INFO [2020-01-12 13:06:10,651] ({pool-2-thread-4} HiveMetaStore.java[logInfo]:746) - 0: get_database: global_temp
 INFO [2020-01-12 13:06:10,652] ({pool-2-thread-4} HiveMetaStore.java[logAuditEvent]:371) - ugi=root	ip=unknown-ip-addr	cmd=get_database: global_temp	
 WARN [2020-01-12 13:06:10,654] ({pool-2-thread-4} ObjectStore.java[getDatabase]:568) - Failed to get database global_temp, returning NoSuchObjectException
 INFO [2020-01-12 13:06:10,675] ({pool-2-thread-4} SparkInterpreter.java[createSparkSession]:362) - Created Spark session with Hive support
 INFO [2020-01-12 13:06:33,502] ({pool-2-thread-4} SparkInterpreter.java[populateSparkWebUrl]:997) - Sending metainfos to Zeppelin server: {url=http://172.18.0.2:4040}
 INFO [2020-01-12 13:06:36,557] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578834335977 finished by scheduler interpreter_1602312349
 INFO [2020-01-12 13:07:00,781] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578834420769 started by scheduler interpreter_1602312349
 INFO [2020-01-12 13:07:02,987] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: collect at <stdin>:11
 INFO [2020-01-12 13:07:03,156] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 0 (collect at <stdin>:11) with 4 output partitions
 INFO [2020-01-12 13:07:03,160] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 0 (collect at <stdin>:11)
 INFO [2020-01-12 13:07:03,170] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:07:03,207] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:07:03,305] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 0 (CartesianRDD[1] at cartesian at NativeMethodAccessorImpl.java:0), which has no missing parents
 INFO [2020-01-12 13:07:04,077] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_0 stored as values in memory (estimated size 1816.0 B, free 413.9 MB)
 INFO [2020-01-12 13:07:04,461] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1136.0 B, free 413.9 MB)
 INFO [2020-01-12 13:07:04,476] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Added broadcast_0_piece0 in memory on 172.18.0.2:34393 (size: 1136.0 B, free: 413.9 MB)
 INFO [2020-01-12 13:07:04,504] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 0 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:07:04,560] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 4 missing tasks from ResultStage 0 (CartesianRDD[1] at cartesian at NativeMethodAccessorImpl.java:0)
 INFO [2020-01-12 13:07:04,577] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 0.0 with 4 tasks
 INFO [2020-01-12 13:07:04,660] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_0.0 tasks to pool default
 INFO [2020-01-12 13:07:04,973] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7391 bytes)
 INFO [2020-01-12 13:07:05,032] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 8367 bytes)
 INFO [2020-01-12 13:07:05,080] ({Executor task launch worker-1} Logging.scala[logInfo]:54) - Running task 1.0 in stage 0.0 (TID 1)
 INFO [2020-01-12 13:07:05,084] ({Executor task launch worker-0} Logging.scala[logInfo]:54) - Running task 0.0 in stage 0.0 (TID 0)
 INFO [2020-01-12 13:07:05,139] ({Executor task launch worker-1} Logging.scala[logInfo]:54) - Fetching file:/zeppelin/interpreter/spark/pyspark/py4j-0.10.4-src.zip with timestamp 1578834348567
 INFO [2020-01-12 13:07:05,642] ({Executor task launch worker-1} Logging.scala[logInfo]:54) - /zeppelin/interpreter/spark/pyspark/py4j-0.10.4-src.zip has been previously copied to /tmp/spark-3fe95cff-4c85-44b1-b78b-d9d51834d0b0/userFiles-dec7a40c-cbbe-47c0-934e-52f79ec6064b/py4j-0.10.4-src.zip
 INFO [2020-01-12 13:07:05,718] ({Executor task launch worker-1} Logging.scala[logInfo]:54) - Fetching file:/zeppelin/interpreter/spark/pyspark/pyspark.zip with timestamp 1578834348493
 INFO [2020-01-12 13:07:05,765] ({Executor task launch worker-1} Logging.scala[logInfo]:54) - /zeppelin/interpreter/spark/pyspark/pyspark.zip has been previously copied to /tmp/spark-3fe95cff-4c85-44b1-b78b-d9d51834d0b0/userFiles-dec7a40c-cbbe-47c0-934e-52f79ec6064b/pyspark.zip
 INFO [2020-01-12 13:07:06,139] ({Executor task launch worker-0} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 0.0 (TID 0). 2040 bytes result sent to driver
 INFO [2020-01-12 13:07:06,152] ({Executor task launch worker-1} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 0.0 (TID 1). 2982 bytes result sent to driver
 INFO [2020-01-12 13:07:06,170] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 8367 bytes)
 INFO [2020-01-12 13:07:06,177] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 7391 bytes)
 INFO [2020-01-12 13:07:06,186] ({Executor task launch worker-1} Logging.scala[logInfo]:54) - Running task 2.0 in stage 0.0 (TID 2)
 INFO [2020-01-12 13:07:06,188] ({Executor task launch worker-0} Logging.scala[logInfo]:54) - Running task 3.0 in stage 0.0 (TID 3)
 INFO [2020-01-12 13:07:06,213] ({Executor task launch worker-0} Logging.scala[logInfo]:54) - Finished task 3.0 in stage 0.0 (TID 3). 1953 bytes result sent to driver
 INFO [2020-01-12 13:07:06,228] ({Executor task launch worker-1} Logging.scala[logInfo]:54) - Finished task 2.0 in stage 0.0 (TID 2). 2895 bytes result sent to driver
 INFO [2020-01-12 13:07:06,247] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 0.0 (TID 1) in 1211 ms on localhost (executor driver) (1/4)
 INFO [2020-01-12 13:07:06,308] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 0.0 (TID 0) in 1558 ms on localhost (executor driver) (2/4)
 INFO [2020-01-12 13:07:06,318] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 3.0 in stage 0.0 (TID 3) in 143 ms on localhost (executor driver) (3/4)
 INFO [2020-01-12 13:07:06,322] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 2.0 in stage 0.0 (TID 2) in 160 ms on localhost (executor driver) (4/4)
 INFO [2020-01-12 13:07:06,326] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 0 (collect at <stdin>:11) finished in 1.649 s
 INFO [2020-01-12 13:07:06,345] ({task-result-getter-3} Logging.scala[logInfo]:54) - Removed TaskSet 0.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:07:06,371] ({Thread-27} Logging.scala[logInfo]:54) - Job 0 finished: collect at <stdin>:11, took 3.382397 s
 INFO [2020-01-12 13:07:12,317] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578834420769 finished by scheduler interpreter_1602312349
 INFO [2020-01-12 13:08:16,386] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578834496385 started by scheduler interpreter_1602312349
 INFO [2020-01-12 13:08:16,688] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: collect at <stdin>:11
 INFO [2020-01-12 13:08:16,712] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 1 (collect at <stdin>:11) with 2 output partitions
 INFO [2020-01-12 13:08:16,713] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 1 (collect at <stdin>:11)
 INFO [2020-01-12 13:08:16,714] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:08:16,716] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:08:16,721] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 1 (ParallelCollectionRDD[2] at parallelize at PythonRDD.scala:475), which has no missing parents
 INFO [2020-01-12 13:08:16,727] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_1 stored as values in memory (estimated size 1360.0 B, free 413.9 MB)
 INFO [2020-01-12 13:08:17,238] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_1_piece0 stored as bytes in memory (estimated size 894.0 B, free 413.9 MB)
 INFO [2020-01-12 13:08:17,259] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Added broadcast_1_piece0 in memory on 172.18.0.2:34393 (size: 894.0 B, free: 413.9 MB)
 INFO [2020-01-12 13:08:17,262] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 1 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:08:17,263] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 2 missing tasks from ResultStage 1 (ParallelCollectionRDD[2] at parallelize at PythonRDD.scala:475)
 INFO [2020-01-12 13:08:17,264] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 1.0 with 2 tasks
 INFO [2020-01-12 13:08:17,266] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_1.0 tasks to pool default
 INFO [2020-01-12 13:08:17,270] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 1.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 7187 bytes)
 INFO [2020-01-12 13:08:17,274] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 1.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 7187 bytes)
 INFO [2020-01-12 13:08:17,284] ({Executor task launch worker-2} Logging.scala[logInfo]:54) - Running task 0.0 in stage 1.0 (TID 4)
 INFO [2020-01-12 13:08:17,284] ({Executor task launch worker-3} Logging.scala[logInfo]:54) - Running task 1.0 in stage 1.0 (TID 5)
 INFO [2020-01-12 13:08:17,330] ({Executor task launch worker-2} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 1.0 (TID 4). 1869 bytes result sent to driver
 INFO [2020-01-12 13:08:17,333] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 1.0 (TID 4) in 66 ms on localhost (executor driver) (1/2)
 INFO [2020-01-12 13:08:17,335] ({Executor task launch worker-3} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 1.0 (TID 5). 1956 bytes result sent to driver
 INFO [2020-01-12 13:08:17,336] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 1.0 (TID 5) in 65 ms on localhost (executor driver) (2/2)
 INFO [2020-01-12 13:08:17,342] ({task-result-getter-0} Logging.scala[logInfo]:54) - Removed TaskSet 1.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:08:17,337] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 1 (collect at <stdin>:11) finished in 0.070 s
 INFO [2020-01-12 13:08:17,345] ({Thread-27} Logging.scala[logInfo]:54) - Job 1 finished: collect at <stdin>:11, took 0.653112 s
 INFO [2020-01-12 13:08:17,414] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578834496385 finished by scheduler interpreter_1602312349
 INFO [2020-01-12 13:08:33,433] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578834513432 started by scheduler interpreter_1602312349
 INFO [2020-01-12 13:08:33,772] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: runJob at PythonRDD.scala:441
 INFO [2020-01-12 13:08:33,781] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 2 (runJob at PythonRDD.scala:441) with 1 output partitions
 INFO [2020-01-12 13:08:33,782] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 2 (runJob at PythonRDD.scala:441)
 INFO [2020-01-12 13:08:33,782] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:08:33,782] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:08:33,783] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 2 (PythonRDD[5] at RDD at PythonRDD.scala:48), which has no missing parents
 INFO [2020-01-12 13:08:33,848] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_2 stored as values in memory (estimated size 4.1 KB, free 413.9 MB)
 INFO [2020-01-12 13:08:34,016] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 413.9 MB)
 INFO [2020-01-12 13:08:34,020] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Added broadcast_2_piece0 in memory on 172.18.0.2:34393 (size: 2.7 KB, free: 413.9 MB)
 INFO [2020-01-12 13:08:34,022] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 2 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:08:34,023] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 1 missing tasks from ResultStage 2 (PythonRDD[5] at RDD at PythonRDD.scala:48)
 INFO [2020-01-12 13:08:34,023] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 2.0 with 1 tasks
 INFO [2020-01-12 13:08:34,024] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_2.0 tasks to pool default
 INFO [2020-01-12 13:08:34,030] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 2.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 7266 bytes)
 INFO [2020-01-12 13:08:34,033] ({Executor task launch worker-3} Logging.scala[logInfo]:54) - Running task 0.0 in stage 2.0 (TID 6)
 INFO [2020-01-12 13:08:35,443] ({Executor task launch worker-3} Logging.scala[logInfo]:54) - Times: total = 1363, boot = 1299, init = 63, finish = 1
 INFO [2020-01-12 13:08:35,458] ({Executor task launch worker-3} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 2.0 (TID 6). 2898 bytes result sent to driver
 INFO [2020-01-12 13:08:35,463] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 2.0 (TID 6) in 1436 ms on localhost (executor driver) (1/1)
 INFO [2020-01-12 13:08:35,466] ({task-result-getter-2} Logging.scala[logInfo]:54) - Removed TaskSet 2.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:08:35,476] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 2 (runJob at PythonRDD.scala:441) finished in 1.452 s
 INFO [2020-01-12 13:08:35,481] ({Thread-27} Logging.scala[logInfo]:54) - Job 2 finished: runJob at PythonRDD.scala:441, took 1.706579 s
 INFO [2020-01-12 13:08:35,510] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578834513432 finished by scheduler interpreter_1602312349
 INFO [2020-01-12 13:09:57,970] ({pool-2-thread-6} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578834597969 started by scheduler interpreter_1602312349
 INFO [2020-01-12 13:09:58,262] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: runJob at PythonRDD.scala:441
 INFO [2020-01-12 13:09:58,265] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 3 (runJob at PythonRDD.scala:441) with 1 output partitions
 INFO [2020-01-12 13:09:58,265] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 3 (runJob at PythonRDD.scala:441)
 INFO [2020-01-12 13:09:58,266] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:09:58,267] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:09:58,270] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 3 (PythonRDD[8] at RDD at PythonRDD.scala:48), which has no missing parents
 INFO [2020-01-12 13:09:58,294] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_3 stored as values in memory (estimated size 4.8 KB, free 413.9 MB)
 INFO [2020-01-12 13:09:58,784] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.2 KB, free 413.9 MB)
 INFO [2020-01-12 13:09:58,785] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Added broadcast_3_piece0 in memory on 172.18.0.2:34393 (size: 3.2 KB, free: 413.9 MB)
 INFO [2020-01-12 13:09:58,794] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 3 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:09:58,798] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 1 missing tasks from ResultStage 3 (PythonRDD[8] at RDD at PythonRDD.scala:48)
 INFO [2020-01-12 13:09:58,798] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 3.0 with 1 tasks
 INFO [2020-01-12 13:09:58,799] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_3.0 tasks to pool default
 INFO [2020-01-12 13:09:58,816] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 3.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 7266 bytes)
 INFO [2020-01-12 13:09:58,826] ({Executor task launch worker-4} Logging.scala[logInfo]:54) - Running task 0.0 in stage 3.0 (TID 7)
ERROR [2020-01-12 13:09:58,932] ({Executor task launch worker-4} Logging.scala[logError]:91) - Exception in task 0.0 in stage 3.0 (TID 7)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
  File "<stdin>", line 11, in <lambda>
TypeError: radial_kernel() takes exactly 3 arguments (2 given)

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
 WARN [2020-01-12 13:09:59,119] ({task-result-getter-3} Logging.scala[logWarning]:66) - Lost task 0.0 in stage 3.0 (TID 7, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
  File "<stdin>", line 11, in <lambda>
TypeError: radial_kernel() takes exactly 3 arguments (2 given)

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

ERROR [2020-01-12 13:09:59,128] ({task-result-getter-3} Logging.scala[logError]:70) - Task 0 in stage 3.0 failed 1 times; aborting job
 INFO [2020-01-12 13:09:59,132] ({task-result-getter-3} Logging.scala[logInfo]:54) - Removed TaskSet 3.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:09:59,161] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Cancelling stage 3
 INFO [2020-01-12 13:09:59,166] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 3 (runJob at PythonRDD.scala:441) failed in 0.365 s due to Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 7, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/rdd.py", line 1339, in takeUpToNumLeft
  File "<stdin>", line 11, in <lambda>
TypeError: radial_kernel() takes exactly 3 arguments (2 given)

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
 INFO [2020-01-12 13:09:59,171] ({Thread-27} Logging.scala[logInfo]:54) - Job 3 failed: runJob at PythonRDD.scala:441, took 0.908852 s
 INFO [2020-01-12 13:09:59,304] ({pool-2-thread-6} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578834597969 finished by scheduler interpreter_1602312349
 INFO [2020-01-12 13:10:21,466] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578834621465 started by scheduler interpreter_1602312349
 INFO [2020-01-12 13:10:21,830] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: runJob at PythonRDD.scala:441
 INFO [2020-01-12 13:10:21,833] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 4 (runJob at PythonRDD.scala:441) with 1 output partitions
 INFO [2020-01-12 13:10:21,833] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 4 (runJob at PythonRDD.scala:441)
 INFO [2020-01-12 13:10:21,834] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:10:21,834] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:10:21,835] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 4 (PythonRDD[11] at RDD at PythonRDD.scala:48), which has no missing parents
 INFO [2020-01-12 13:10:21,846] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_4 stored as values in memory (estimated size 4.8 KB, free 413.9 MB)
 INFO [2020-01-12 13:10:22,096] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.2 KB, free 413.9 MB)
 INFO [2020-01-12 13:10:22,102] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Added broadcast_4_piece0 in memory on 172.18.0.2:34393 (size: 3.2 KB, free: 413.9 MB)
 INFO [2020-01-12 13:10:22,106] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 4 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:10:22,107] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 1 missing tasks from ResultStage 4 (PythonRDD[11] at RDD at PythonRDD.scala:48)
 INFO [2020-01-12 13:10:22,107] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 4.0 with 1 tasks
 INFO [2020-01-12 13:10:22,109] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_4.0 tasks to pool default
 INFO [2020-01-12 13:10:22,132] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 4.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 7266 bytes)
 INFO [2020-01-12 13:10:22,135] ({Executor task launch worker-4} Logging.scala[logInfo]:54) - Running task 0.0 in stage 4.0 (TID 8)
 INFO [2020-01-12 13:10:22,173] ({Executor task launch worker-4} Logging.scala[logInfo]:54) - Times: total = 18, boot = 4, init = 13, finish = 1
 INFO [2020-01-12 13:10:22,184] ({Executor task launch worker-4} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 4.0 (TID 8). 2118 bytes result sent to driver
 INFO [2020-01-12 13:10:22,188] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 4.0 (TID 8) in 73 ms on localhost (executor driver) (1/1)
 INFO [2020-01-12 13:10:22,190] ({task-result-getter-1} Logging.scala[logInfo]:54) - Removed TaskSet 4.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:10:22,206] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 4 (runJob at PythonRDD.scala:441) finished in 0.095 s
 INFO [2020-01-12 13:10:22,207] ({Thread-27} Logging.scala[logInfo]:54) - Job 4 finished: runJob at PythonRDD.scala:441, took 0.376589 s
 INFO [2020-01-12 13:10:22,241] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578834621465 finished by scheduler interpreter_1602312349
 INFO [2020-01-12 13:15:44,910] ({pool-2-thread-7} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578834944909 started by scheduler interpreter_1602312349
 INFO [2020-01-12 13:15:52,604] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Removed broadcast_4_piece0 on 172.18.0.2:34393 in memory (size: 3.2 KB, free: 413.9 MB)
 INFO [2020-01-12 13:15:52,637] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_0_piece0 on 172.18.0.2:34393 in memory (size: 1136.0 B, free: 413.9 MB)
 INFO [2020-01-12 13:15:52,670] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Removed broadcast_1_piece0 on 172.18.0.2:34393 in memory (size: 894.0 B, free: 413.9 MB)
 INFO [2020-01-12 13:15:52,691] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_2_piece0 on 172.18.0.2:34393 in memory (size: 2.7 KB, free: 413.9 MB)
 INFO [2020-01-12 13:15:52,717] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_3_piece0 on 172.18.0.2:34393 in memory (size: 3.2 KB, free: 413.9 MB)
 INFO [2020-01-12 13:15:52,786] ({pool-2-thread-7} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578834944909 finished by scheduler interpreter_1602312349
 INFO [2020-01-12 13:16:11,931] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578834971923 started by scheduler interpreter_1602312349
 INFO [2020-01-12 13:16:12,107] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578834971923 finished by scheduler interpreter_1602312349
 INFO [2020-01-12 13:18:16,659] ({pool-2-thread-8} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578835096658 started by scheduler interpreter_1602312349
 INFO [2020-01-12 13:18:16,807] ({pool-2-thread-8} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578835096658 finished by scheduler interpreter_1602312349
 INFO [2020-01-12 13:18:41,350] ({pool-2-thread-6} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578835121345 started by scheduler interpreter_1602312349
 INFO [2020-01-12 13:18:41,818] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: collect at <stdin>:14
 INFO [2020-01-12 13:18:41,824] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 5 (collect at <stdin>:14) with 4 output partitions
 INFO [2020-01-12 13:18:41,825] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 5 (collect at <stdin>:14)
 INFO [2020-01-12 13:18:41,826] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:18:41,827] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:18:41,831] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 5 (PythonRDD[24] at collect at <stdin>:14), which has no missing parents
 INFO [2020-01-12 13:18:41,843] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_5 stored as values in memory (estimated size 4.3 KB, free 413.9 MB)
 INFO [2020-01-12 13:18:42,246] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 413.9 MB)
 INFO [2020-01-12 13:18:42,251] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Added broadcast_5_piece0 in memory on 172.18.0.2:34393 (size: 2.9 KB, free: 413.9 MB)
 INFO [2020-01-12 13:18:42,256] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 5 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:18:42,259] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 4 missing tasks from ResultStage 5 (PythonRDD[24] at collect at <stdin>:14)
 INFO [2020-01-12 13:18:42,261] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 5.0 with 4 tasks
 INFO [2020-01-12 13:18:42,269] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_5.0 tasks to pool default
 INFO [2020-01-12 13:18:42,288] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 5.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 6669 bytes)
 INFO [2020-01-12 13:18:42,303] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 5.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 6922 bytes)
 INFO [2020-01-12 13:18:42,309] ({Executor task launch worker-6} Logging.scala[logInfo]:54) - Running task 1.0 in stage 5.0 (TID 10)
 INFO [2020-01-12 13:18:42,312] ({Executor task launch worker-5} Logging.scala[logInfo]:54) - Running task 0.0 in stage 5.0 (TID 9)
 INFO [2020-01-12 13:18:42,422] ({Executor task launch worker-6} Logging.scala[logInfo]:54) - Times: total = 95, boot = 51, init = 15, finish = 29
 INFO [2020-01-12 13:18:42,460] ({Executor task launch worker-6} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 5.0 (TID 10). 2484 bytes result sent to driver
 INFO [2020-01-12 13:18:42,505] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 2.0 in stage 5.0 (TID 11, localhost, executor driver, partition 2, PROCESS_LOCAL, 6922 bytes)
 INFO [2020-01-12 13:18:42,507] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 5.0 (TID 10) in 218 ms on localhost (executor driver) (1/4)
 INFO [2020-01-12 13:18:42,508] ({Executor task launch worker-6} Logging.scala[logInfo]:54) - Running task 2.0 in stage 5.0 (TID 11)
 INFO [2020-01-12 13:18:42,524] ({Executor task launch worker-5} Logging.scala[logInfo]:54) - Times: total = 61, boot = 27, init = 32, finish = 2
 INFO [2020-01-12 13:18:42,554] ({Executor task launch worker-5} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 5.0 (TID 9). 2484 bytes result sent to driver
 INFO [2020-01-12 13:18:42,596] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 3.0 in stage 5.0 (TID 12, localhost, executor driver, partition 3, PROCESS_LOCAL, 6669 bytes)
 INFO [2020-01-12 13:18:42,601] ({Executor task launch worker-5} Logging.scala[logInfo]:54) - Running task 3.0 in stage 5.0 (TID 12)
 INFO [2020-01-12 13:18:42,598] ({Executor task launch worker-6} Logging.scala[logInfo]:54) - Times: total = 77, boot = 27, init = 46, finish = 4
 INFO [2020-01-12 13:18:42,623] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 5.0 (TID 9) in 348 ms on localhost (executor driver) (2/4)
 INFO [2020-01-12 13:18:42,661] ({Executor task launch worker-6} Logging.scala[logInfo]:54) - Finished task 2.0 in stage 5.0 (TID 11). 2571 bytes result sent to driver
 INFO [2020-01-12 13:18:42,733] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 2.0 in stage 5.0 (TID 11) in 272 ms on localhost (executor driver) (3/4)
 INFO [2020-01-12 13:18:42,784] ({Executor task launch worker-5} Logging.scala[logInfo]:54) - Times: total = 137, boot = -88, init = 224, finish = 1
 INFO [2020-01-12 13:18:42,788] ({Executor task launch worker-5} Logging.scala[logInfo]:54) - Finished task 3.0 in stage 5.0 (TID 12). 2484 bytes result sent to driver
 INFO [2020-01-12 13:18:42,805] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 3.0 in stage 5.0 (TID 12) in 227 ms on localhost (executor driver) (4/4)
 INFO [2020-01-12 13:18:42,805] ({task-result-getter-1} Logging.scala[logInfo]:54) - Removed TaskSet 5.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:18:42,818] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 5 (collect at <stdin>:14) finished in 0.546 s
 INFO [2020-01-12 13:18:42,823] ({Thread-27} Logging.scala[logInfo]:54) - Job 5 finished: collect at <stdin>:14, took 1.001096 s
 INFO [2020-01-12 13:18:43,523] ({pool-2-thread-6} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578835121345 finished by scheduler interpreter_1602312349
 INFO [2020-01-12 13:18:59,288] ({pool-2-thread-9} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578835139279 started by scheduler interpreter_1602312349
 INFO [2020-01-12 13:19:00,007] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: collect at <stdin>:14
 INFO [2020-01-12 13:19:00,043] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 6 (collect at <stdin>:14) with 4 output partitions
 INFO [2020-01-12 13:19:00,044] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 6 (collect at <stdin>:14)
 INFO [2020-01-12 13:19:00,044] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:19:00,051] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:19:00,052] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 6 (PythonRDD[28] at collect at <stdin>:14), which has no missing parents
 INFO [2020-01-12 13:19:00,079] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_6 stored as values in memory (estimated size 4.3 KB, free 413.9 MB)
 INFO [2020-01-12 13:19:00,345] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_6_piece0 stored as bytes in memory (estimated size 2.9 KB, free 413.9 MB)
 INFO [2020-01-12 13:19:00,356] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Added broadcast_6_piece0 in memory on 172.18.0.2:34393 (size: 2.9 KB, free: 413.9 MB)
 INFO [2020-01-12 13:19:00,362] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 6 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:19:00,363] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 4 missing tasks from ResultStage 6 (PythonRDD[28] at collect at <stdin>:14)
 INFO [2020-01-12 13:19:00,363] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 6.0 with 4 tasks
 INFO [2020-01-12 13:19:00,365] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_6.0 tasks to pool default
 INFO [2020-01-12 13:19:00,389] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 6.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6669 bytes)
 INFO [2020-01-12 13:19:00,409] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 6.0 (TID 14, localhost, executor driver, partition 1, PROCESS_LOCAL, 6922 bytes)
 INFO [2020-01-12 13:19:00,420] ({Executor task launch worker-5} Logging.scala[logInfo]:54) - Running task 0.0 in stage 6.0 (TID 13)
 INFO [2020-01-12 13:19:00,420] ({Executor task launch worker-6} Logging.scala[logInfo]:54) - Running task 1.0 in stage 6.0 (TID 14)
 INFO [2020-01-12 13:19:00,644] ({Executor task launch worker-5} Logging.scala[logInfo]:54) - Times: total = 54, boot = -17794, init = 17847, finish = 1
 INFO [2020-01-12 13:19:00,644] ({Executor task launch worker-6} Logging.scala[logInfo]:54) - Times: total = 71, boot = -17941, init = 18011, finish = 1
 INFO [2020-01-12 13:19:00,662] ({Executor task launch worker-5} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 6.0 (TID 13). 2484 bytes result sent to driver
 INFO [2020-01-12 13:19:00,674] ({Executor task launch worker-6} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 6.0 (TID 14). 2571 bytes result sent to driver
 INFO [2020-01-12 13:19:00,709] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 2.0 in stage 6.0 (TID 15, localhost, executor driver, partition 2, PROCESS_LOCAL, 6922 bytes)
 INFO [2020-01-12 13:19:00,711] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 6.0 (TID 13) in 343 ms on localhost (executor driver) (1/4)
 INFO [2020-01-12 13:19:00,719] ({Executor task launch worker-6} Logging.scala[logInfo]:54) - Running task 2.0 in stage 6.0 (TID 15)
 INFO [2020-01-12 13:19:00,741] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 3.0 in stage 6.0 (TID 16, localhost, executor driver, partition 3, PROCESS_LOCAL, 6669 bytes)
 INFO [2020-01-12 13:19:00,748] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 6.0 (TID 14) in 359 ms on localhost (executor driver) (2/4)
 INFO [2020-01-12 13:19:00,752] ({Executor task launch worker-5} Logging.scala[logInfo]:54) - Running task 3.0 in stage 6.0 (TID 16)
 INFO [2020-01-12 13:19:00,835] ({Executor task launch worker-6} Logging.scala[logInfo]:54) - Times: total = 76, boot = -98, init = 172, finish = 2
 INFO [2020-01-12 13:19:00,857] ({Executor task launch worker-6} Logging.scala[logInfo]:54) - Finished task 2.0 in stage 6.0 (TID 15). 2484 bytes result sent to driver
 INFO [2020-01-12 13:19:00,864] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 2.0 in stage 6.0 (TID 15) in 201 ms on localhost (executor driver) (3/4)
 INFO [2020-01-12 13:19:00,893] ({Executor task launch worker-5} Logging.scala[logInfo]:54) - Times: total = 64, boot = -159, init = 222, finish = 1
 INFO [2020-01-12 13:19:00,904] ({Executor task launch worker-5} Logging.scala[logInfo]:54) - Finished task 3.0 in stage 6.0 (TID 16). 2571 bytes result sent to driver
 INFO [2020-01-12 13:19:00,916] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 3.0 in stage 6.0 (TID 16) in 192 ms on localhost (executor driver) (4/4)
 INFO [2020-01-12 13:19:00,917] ({task-result-getter-1} Logging.scala[logInfo]:54) - Removed TaskSet 6.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:19:00,920] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 6 (collect at <stdin>:14) finished in 0.553 s
 INFO [2020-01-12 13:19:00,922] ({Thread-27} Logging.scala[logInfo]:54) - Job 6 finished: collect at <stdin>:14, took 0.914118 s
 INFO [2020-01-12 13:19:01,119] ({pool-2-thread-9} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578835139279 finished by scheduler interpreter_1602312349
 INFO [2020-01-12 13:29:21,541] ({pool-2-thread-5} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578835761541 started by scheduler interpreter_1602312349
 INFO [2020-01-12 13:29:21,590] ({pool-2-thread-5} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578835761541 finished by scheduler interpreter_1602312349
 INFO [2020-01-12 13:29:30,055] ({pool-2-thread-10} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578835770053 started by scheduler interpreter_1602312349
 INFO [2020-01-12 13:29:30,182] ({pool-2-thread-10} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578835770053 finished by scheduler interpreter_1602312349
 INFO [2020-01-12 13:29:45,600] ({pool-2-thread-7} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578835785586 started by scheduler interpreter_1602312349
 INFO [2020-01-12 13:29:45,733] ({pool-2-thread-7} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578835785586 finished by scheduler interpreter_1602312349
 INFO [2020-01-12 13:31:31,922] ({pool-2-thread-11} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578835891921 started by scheduler interpreter_1602312349
 INFO [2020-01-12 13:31:32,279] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: zipWithIndex at <stdin>:11
 INFO [2020-01-12 13:31:32,283] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 7 (zipWithIndex at <stdin>:11) with 2 output partitions
 INFO [2020-01-12 13:31:32,284] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 7 (zipWithIndex at <stdin>:11)
 INFO [2020-01-12 13:31:32,285] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:31:32,286] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:31:32,288] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 7 (PythonRDD[33] at zipWithIndex at <stdin>:11), which has no missing parents
 INFO [2020-01-12 13:31:32,298] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_7 stored as values in memory (estimated size 3.8 KB, free 413.9 MB)
 INFO [2020-01-12 13:31:32,654] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_7_piece0 stored as bytes in memory (estimated size 2.5 KB, free 413.9 MB)
 INFO [2020-01-12 13:31:32,657] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Added broadcast_7_piece0 in memory on 172.18.0.2:34393 (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 13:31:32,662] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 7 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:31:32,665] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 2 missing tasks from ResultStage 7 (PythonRDD[33] at zipWithIndex at <stdin>:11)
 INFO [2020-01-12 13:31:32,666] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 7.0 with 2 tasks
 INFO [2020-01-12 13:31:32,668] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_7.0 tasks to pool default
 INFO [2020-01-12 13:31:32,684] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 7.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 6470 bytes)
 INFO [2020-01-12 13:31:32,699] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 7.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 6470 bytes)
 INFO [2020-01-12 13:31:32,710] ({Executor task launch worker-8} Logging.scala[logInfo]:54) - Running task 1.0 in stage 7.0 (TID 18)
 INFO [2020-01-12 13:31:32,718] ({Executor task launch worker-7} Logging.scala[logInfo]:54) - Running task 0.0 in stage 7.0 (TID 17)
 INFO [2020-01-12 13:31:32,865] ({Executor task launch worker-7} Logging.scala[logInfo]:54) - Times: total = 73, boot = 23, init = 49, finish = 1
 INFO [2020-01-12 13:31:32,867] ({Executor task launch worker-8} Logging.scala[logInfo]:54) - Times: total = 98, boot = 36, init = 61, finish = 1
 INFO [2020-01-12 13:31:32,879] ({Executor task launch worker-8} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 7.0 (TID 18). 1658 bytes result sent to driver
 INFO [2020-01-12 13:31:32,880] ({Executor task launch worker-7} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 7.0 (TID 17). 1658 bytes result sent to driver
 INFO [2020-01-12 13:31:32,907] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 7.0 (TID 18) in 221 ms on localhost (executor driver) (1/2)
 INFO [2020-01-12 13:31:32,954] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 7.0 (TID 17) in 274 ms on localhost (executor driver) (2/2)
 INFO [2020-01-12 13:31:32,955] ({task-result-getter-2} Logging.scala[logInfo]:54) - Removed TaskSet 7.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:31:33,055] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 7 (zipWithIndex at <stdin>:11) finished in 0.385 s
 INFO [2020-01-12 13:31:33,062] ({Thread-27} Logging.scala[logInfo]:54) - Job 7 finished: zipWithIndex at <stdin>:11, took 0.778973 s
 INFO [2020-01-12 13:31:33,253] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: zipWithIndex at <stdin>:12
 INFO [2020-01-12 13:31:33,261] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 8 (zipWithIndex at <stdin>:12) with 2 output partitions
 INFO [2020-01-12 13:31:33,262] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 8 (zipWithIndex at <stdin>:12)
 INFO [2020-01-12 13:31:33,262] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:31:33,262] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:31:33,263] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 8 (PythonRDD[35] at zipWithIndex at <stdin>:12), which has no missing parents
 INFO [2020-01-12 13:31:33,273] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_8 stored as values in memory (estimated size 3.8 KB, free 413.9 MB)
 INFO [2020-01-12 13:31:33,769] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_8_piece0 stored as bytes in memory (estimated size 2.5 KB, free 413.9 MB)
 INFO [2020-01-12 13:31:33,779] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Added broadcast_8_piece0 in memory on 172.18.0.2:34393 (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 13:31:33,792] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 8 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:31:33,798] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 2 missing tasks from ResultStage 8 (PythonRDD[35] at zipWithIndex at <stdin>:12)
 INFO [2020-01-12 13:31:33,799] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 8.0 with 2 tasks
 INFO [2020-01-12 13:31:33,802] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_8.0 tasks to pool default
 INFO [2020-01-12 13:31:33,814] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 8.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 6428 bytes)
 INFO [2020-01-12 13:31:33,821] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 8.0 (TID 20, localhost, executor driver, partition 1, PROCESS_LOCAL, 6428 bytes)
 INFO [2020-01-12 13:31:33,834] ({Executor task launch worker-8} Logging.scala[logInfo]:54) - Running task 1.0 in stage 8.0 (TID 20)
 INFO [2020-01-12 13:31:33,835] ({Executor task launch worker-7} Logging.scala[logInfo]:54) - Running task 0.0 in stage 8.0 (TID 19)
 INFO [2020-01-12 13:31:33,940] ({Executor task launch worker-8} Logging.scala[logInfo]:54) - Times: total = 72, boot = -847, init = 919, finish = 0
 INFO [2020-01-12 13:31:33,949] ({Executor task launch worker-7} Logging.scala[logInfo]:54) - Times: total = 78, boot = -856, init = 933, finish = 1
 INFO [2020-01-12 13:31:33,963] ({Executor task launch worker-7} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 8.0 (TID 19). 1571 bytes result sent to driver
 INFO [2020-01-12 13:31:33,999] ({Executor task launch worker-8} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 8.0 (TID 20). 1571 bytes result sent to driver
 INFO [2020-01-12 13:31:34,030] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 8.0 (TID 20) in 214 ms on localhost (executor driver) (1/2)
 INFO [2020-01-12 13:31:34,038] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 8.0 (TID 19) in 230 ms on localhost (executor driver) (2/2)
 INFO [2020-01-12 13:31:34,039] ({task-result-getter-3} Logging.scala[logInfo]:54) - Removed TaskSet 8.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:31:34,085] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 8 (zipWithIndex at <stdin>:12) finished in 0.281 s
 INFO [2020-01-12 13:31:34,088] ({Thread-27} Logging.scala[logInfo]:54) - Job 8 finished: zipWithIndex at <stdin>:12, took 0.833781 s
 INFO [2020-01-12 13:31:34,270] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: collect at <stdin>:14
 INFO [2020-01-12 13:31:34,273] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 9 (collect at <stdin>:14) with 4 output partitions
 INFO [2020-01-12 13:31:34,274] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 9 (collect at <stdin>:14)
 INFO [2020-01-12 13:31:34,274] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:31:34,275] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:31:34,279] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 9 (PythonRDD[38] at collect at <stdin>:14), which has no missing parents
 INFO [2020-01-12 13:31:34,398] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_9 stored as values in memory (estimated size 5.1 KB, free 413.9 MB)
 INFO [2020-01-12 13:31:34,856] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.2 KB, free 413.9 MB)
 INFO [2020-01-12 13:31:34,860] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Added broadcast_9_piece0 in memory on 172.18.0.2:34393 (size: 3.2 KB, free: 413.9 MB)
 INFO [2020-01-12 13:31:34,862] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 9 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:31:34,863] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 4 missing tasks from ResultStage 9 (PythonRDD[38] at collect at <stdin>:14)
 INFO [2020-01-12 13:31:34,863] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 9.0 with 4 tasks
 INFO [2020-01-12 13:31:34,864] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_9.0 tasks to pool default
 INFO [2020-01-12 13:31:34,872] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 6669 bytes)
 INFO [2020-01-12 13:31:34,879] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 9.0 (TID 22, localhost, executor driver, partition 1, PROCESS_LOCAL, 6922 bytes)
 INFO [2020-01-12 13:31:34,883] ({Executor task launch worker-8} Logging.scala[logInfo]:54) - Running task 0.0 in stage 9.0 (TID 21)
 INFO [2020-01-12 13:31:34,883] ({Executor task launch worker-7} Logging.scala[logInfo]:54) - Running task 1.0 in stage 9.0 (TID 22)
 INFO [2020-01-12 13:31:35,073] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 40, boot = 4, init = 35, finish = 1
 INFO [2020-01-12 13:31:35,079] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 41, boot = 9, init = 29, finish = 3
 INFO [2020-01-12 13:31:35,237] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 116, boot = 83, init = 32, finish = 1
 INFO [2020-01-12 13:31:35,237] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 152, boot = 97, init = 54, finish = 1
 INFO [2020-01-12 13:31:35,329] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 71, boot = -906, init = 977, finish = 0
 INFO [2020-01-12 13:31:35,340] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 60, boot = -899, init = 958, finish = 1
 INFO [2020-01-12 13:31:35,411] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 73, boot = -116, init = 189, finish = 0
 INFO [2020-01-12 13:31:35,423] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 61, boot = -97, init = 158, finish = 0
ERROR [2020-01-12 13:31:35,436] ({Executor task launch worker-8} Logging.scala[logError]:91) - Exception in task 0.0 in stage 9.0 (TID 21)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "<stdin>", line 13, in <lambda>
ValueError: need more than 2 values to unpack

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
ERROR [2020-01-12 13:31:35,443] ({Executor task launch worker-7} Logging.scala[logError]:91) - Exception in task 1.0 in stage 9.0 (TID 22)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "<stdin>", line 13, in <lambda>
ValueError: need more than 2 values to unpack

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
 INFO [2020-01-12 13:31:35,487] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 2.0 in stage 9.0 (TID 23, localhost, executor driver, partition 2, PROCESS_LOCAL, 6922 bytes)
 INFO [2020-01-12 13:31:35,503] ({Executor task launch worker-7} Logging.scala[logInfo]:54) - Running task 2.0 in stage 9.0 (TID 23)
 INFO [2020-01-12 13:31:35,518] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 3.0 in stage 9.0 (TID 24, localhost, executor driver, partition 3, PROCESS_LOCAL, 6669 bytes)
 WARN [2020-01-12 13:31:35,520] ({task-result-getter-0} Logging.scala[logWarning]:66) - Lost task 0.0 in stage 9.0 (TID 21, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "<stdin>", line 13, in <lambda>
ValueError: need more than 2 values to unpack

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

ERROR [2020-01-12 13:31:35,522] ({task-result-getter-0} Logging.scala[logError]:70) - Task 0 in stage 9.0 failed 1 times; aborting job
 INFO [2020-01-12 13:31:35,531] ({Executor task launch worker-8} Logging.scala[logInfo]:54) - Running task 3.0 in stage 9.0 (TID 24)
 INFO [2020-01-12 13:31:35,549] ({task-result-getter-2} Logging.scala[logInfo]:54) - Lost task 1.0 in stage 9.0 (TID 22) on localhost, executor driver: org.apache.spark.api.python.PythonException (Traceback (most recent call last):
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "<stdin>", line 13, in <lambda>
ValueError: need more than 2 values to unpack
) [duplicate 1]
 INFO [2020-01-12 13:31:35,550] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Cancelling stage 9
 INFO [2020-01-12 13:31:35,577] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Executor is trying to kill task 3.0 in stage 9.0 (TID 24)
 INFO [2020-01-12 13:31:35,578] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Executor is trying to kill task 2.0 in stage 9.0 (TID 23)
 INFO [2020-01-12 13:31:35,580] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Stage 9 was cancelled
 INFO [2020-01-12 13:31:35,581] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 9 (collect at <stdin>:14) failed in 0.716 s due to Job aborted due to stage failure: Task 0 in stage 9.0 failed 1 times, most recent failure: Lost task 0.0 in stage 9.0 (TID 21, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 174, in main
    process()
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/worker.py", line 169, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/zeppelin/interpreter/spark/pyspark/pyspark.zip/pyspark/serializers.py", line 268, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "<stdin>", line 13, in <lambda>
ValueError: need more than 2 values to unpack

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)
	at org.apache.spark.scheduler.Task.run(Task.scala:99)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:282)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

Driver stacktrace:
 INFO [2020-01-12 13:31:35,583] ({Thread-27} Logging.scala[logInfo]:54) - Job 9 failed: collect at <stdin>:14, took 1.312998 s
 WARN [2020-01-12 13:31:35,608] ({Worker Monitor for python} Logging.scala[logWarning]:66) - Incomplete task interrupted: Attempting to kill Python Worker
 WARN [2020-01-12 13:31:35,627] ({Worker Monitor for python} Logging.scala[logWarning]:66) - Incomplete task interrupted: Attempting to kill Python Worker
 INFO [2020-01-12 13:31:35,669] ({Executor task launch worker-7} Logging.scala[logInfo]:54) - Executor killed task 2.0 in stage 9.0 (TID 23)
 INFO [2020-01-12 13:31:35,671] ({Executor task launch worker-8} Logging.scala[logInfo]:54) - Executor killed task 3.0 in stage 9.0 (TID 24)
ERROR [2020-01-12 13:31:35,674] ({stdout writer for python} Logging.scala[logError]:91) - Uncaught exception in thread stdout writer for python
java.net.SocketException: Socket is closed
	at java.net.Socket.shutdownOutput(Socket.java:1551)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3$$anonfun$apply$3.apply$mcV$sp(PythonRDD.scala:336)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3$$anonfun$apply$3.apply(PythonRDD.scala:336)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3$$anonfun$apply$3.apply(PythonRDD.scala:336)
	at org.apache.spark.util.Utils$.tryLog(Utils.scala:1964)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:336)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)
 WARN [2020-01-12 13:31:35,714] ({task-result-getter-1} Logging.scala[logWarning]:66) - Lost task 3.0 in stage 9.0 (TID 24, localhost, executor driver): TaskKilled (killed intentionally)
 INFO [2020-01-12 13:31:35,720] ({task-result-getter-1} Logging.scala[logInfo]:54) - Removed TaskSet 9.0, whose tasks have all completed, from pool default
 WARN [2020-01-12 13:31:35,720] ({task-result-getter-3} Logging.scala[logWarning]:66) - Lost task 2.0 in stage 9.0 (TID 23, localhost, executor driver): TaskKilled (killed intentionally)
 INFO [2020-01-12 13:31:35,721] ({task-result-getter-3} Logging.scala[logInfo]:54) - Removed TaskSet 9.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:31:35,833] ({pool-2-thread-11} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578835891921 finished by scheduler interpreter_1602312349
 INFO [2020-01-12 13:33:37,528] ({pool-2-thread-4} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578836017527 started by scheduler interpreter_1602312349
 INFO [2020-01-12 13:33:37,849] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: zipWithIndex at <stdin>:11
 INFO [2020-01-12 13:33:37,853] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 10 (zipWithIndex at <stdin>:11) with 2 output partitions
 INFO [2020-01-12 13:33:37,854] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 10 (zipWithIndex at <stdin>:11)
 INFO [2020-01-12 13:33:37,854] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:33:37,855] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:33:37,857] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 10 (PythonRDD[40] at zipWithIndex at <stdin>:11), which has no missing parents
 INFO [2020-01-12 13:33:37,874] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_10 stored as values in memory (estimated size 3.8 KB, free 413.9 MB)
 INFO [2020-01-12 13:33:38,204] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.5 KB, free 413.9 MB)
 INFO [2020-01-12 13:33:38,210] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Added broadcast_10_piece0 in memory on 172.18.0.2:34393 (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 13:33:38,220] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 10 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:33:38,222] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 2 missing tasks from ResultStage 10 (PythonRDD[40] at zipWithIndex at <stdin>:11)
 INFO [2020-01-12 13:33:38,239] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 10.0 with 2 tasks
 INFO [2020-01-12 13:33:38,241] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_10.0 tasks to pool default
 INFO [2020-01-12 13:33:38,287] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 10.0 (TID 25, localhost, executor driver, partition 0, PROCESS_LOCAL, 6470 bytes)
 INFO [2020-01-12 13:33:38,318] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 10.0 (TID 26, localhost, executor driver, partition 1, PROCESS_LOCAL, 6470 bytes)
 INFO [2020-01-12 13:33:38,325] ({Executor task launch worker-9} Logging.scala[logInfo]:54) - Running task 0.0 in stage 10.0 (TID 25)
 INFO [2020-01-12 13:33:38,336] ({Executor task launch worker-10} Logging.scala[logInfo]:54) - Running task 1.0 in stage 10.0 (TID 26)
 INFO [2020-01-12 13:33:38,461] ({Executor task launch worker-9} Logging.scala[logInfo]:54) - Times: total = 76, boot = 25, init = 50, finish = 1
 INFO [2020-01-12 13:33:38,486] ({Executor task launch worker-10} Logging.scala[logInfo]:54) - Times: total = 84, boot = 21, init = 62, finish = 1
 INFO [2020-01-12 13:33:38,487] ({Executor task launch worker-9} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 10.0 (TID 25). 1658 bytes result sent to driver
 INFO [2020-01-12 13:33:38,519] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 10.0 (TID 25) in 272 ms on localhost (executor driver) (1/2)
 INFO [2020-01-12 13:33:38,538] ({Executor task launch worker-10} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 10.0 (TID 26). 1658 bytes result sent to driver
 INFO [2020-01-12 13:33:38,573] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 10.0 (TID 26) in 280 ms on localhost (executor driver) (2/2)
 INFO [2020-01-12 13:33:38,598] ({task-result-getter-2} Logging.scala[logInfo]:54) - Removed TaskSet 10.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:33:38,663] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 10 (zipWithIndex at <stdin>:11) finished in 0.417 s
 INFO [2020-01-12 13:33:38,667] ({Thread-27} Logging.scala[logInfo]:54) - Job 10 finished: zipWithIndex at <stdin>:11, took 0.816338 s
 INFO [2020-01-12 13:33:39,171] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: zipWithIndex at <stdin>:12
 INFO [2020-01-12 13:33:39,174] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 11 (zipWithIndex at <stdin>:12) with 2 output partitions
 INFO [2020-01-12 13:33:39,174] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 11 (zipWithIndex at <stdin>:12)
 INFO [2020-01-12 13:33:39,174] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:33:39,175] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:33:39,175] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 11 (PythonRDD[42] at zipWithIndex at <stdin>:12), which has no missing parents
 INFO [2020-01-12 13:33:39,201] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_11 stored as values in memory (estimated size 3.8 KB, free 413.9 MB)
 INFO [2020-01-12 13:33:39,403] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.5 KB, free 413.9 MB)
 INFO [2020-01-12 13:33:39,405] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Added broadcast_11_piece0 in memory on 172.18.0.2:34393 (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 13:33:39,414] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 11 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:33:39,415] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 2 missing tasks from ResultStage 11 (PythonRDD[42] at zipWithIndex at <stdin>:12)
 INFO [2020-01-12 13:33:39,415] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 11.0 with 2 tasks
 INFO [2020-01-12 13:33:39,417] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_11.0 tasks to pool default
 INFO [2020-01-12 13:33:39,427] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 11.0 (TID 27, localhost, executor driver, partition 0, PROCESS_LOCAL, 6428 bytes)
 INFO [2020-01-12 13:33:39,449] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 11.0 (TID 28, localhost, executor driver, partition 1, PROCESS_LOCAL, 6428 bytes)
 INFO [2020-01-12 13:33:39,532] ({Executor task launch worker-9} Logging.scala[logInfo]:54) - Running task 1.0 in stage 11.0 (TID 28)
 INFO [2020-01-12 13:33:39,542] ({Executor task launch worker-10} Logging.scala[logInfo]:54) - Running task 0.0 in stage 11.0 (TID 27)
 INFO [2020-01-12 13:33:39,632] ({Executor task launch worker-10} Logging.scala[logInfo]:54) - Times: total = 53, boot = -934, init = 987, finish = 0
 INFO [2020-01-12 13:33:39,636] ({Executor task launch worker-10} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 11.0 (TID 27). 1571 bytes result sent to driver
 INFO [2020-01-12 13:33:39,648] ({Executor task launch worker-9} Logging.scala[logInfo]:54) - Times: total = 59, boot = -838, init = 897, finish = 0
 INFO [2020-01-12 13:33:39,652] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 11.0 (TID 27) in 233 ms on localhost (executor driver) (1/2)
 INFO [2020-01-12 13:33:39,656] ({Executor task launch worker-9} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 11.0 (TID 28). 1571 bytes result sent to driver
 INFO [2020-01-12 13:33:39,668] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 11.0 (TID 28) in 239 ms on localhost (executor driver) (2/2)
 INFO [2020-01-12 13:33:39,669] ({task-result-getter-3} Logging.scala[logInfo]:54) - Removed TaskSet 11.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:33:39,678] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 11 (zipWithIndex at <stdin>:12) finished in 0.259 s
 INFO [2020-01-12 13:33:39,679] ({Thread-27} Logging.scala[logInfo]:54) - Job 11 finished: zipWithIndex at <stdin>:12, took 0.506575 s
 INFO [2020-01-12 13:33:39,779] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: collect at <stdin>:13
 INFO [2020-01-12 13:33:39,783] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 12 (collect at <stdin>:13) with 2 output partitions
 INFO [2020-01-12 13:33:39,783] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 12 (collect at <stdin>:13)
 INFO [2020-01-12 13:33:39,786] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:33:39,787] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:33:39,795] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 12 (PythonRDD[43] at collect at <stdin>:13), which has no missing parents
 INFO [2020-01-12 13:33:39,809] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_12 stored as values in memory (estimated size 3.6 KB, free 413.9 MB)
 INFO [2020-01-12 13:33:40,031] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_12_piece0 stored as bytes in memory (estimated size 2.4 KB, free 413.9 MB)
 INFO [2020-01-12 13:33:40,033] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Added broadcast_12_piece0 in memory on 172.18.0.2:34393 (size: 2.4 KB, free: 413.9 MB)
 INFO [2020-01-12 13:33:40,039] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 12 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:33:40,040] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 2 missing tasks from ResultStage 12 (PythonRDD[43] at collect at <stdin>:13)
 INFO [2020-01-12 13:33:40,041] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 12.0 with 2 tasks
 INFO [2020-01-12 13:33:40,042] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_12.0 tasks to pool default
 INFO [2020-01-12 13:33:40,052] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 12.0 (TID 29, localhost, executor driver, partition 0, PROCESS_LOCAL, 6465 bytes)
 INFO [2020-01-12 13:33:40,063] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 12.0 (TID 30, localhost, executor driver, partition 1, PROCESS_LOCAL, 6465 bytes)
 INFO [2020-01-12 13:33:40,069] ({Executor task launch worker-9} Logging.scala[logInfo]:54) - Running task 0.0 in stage 12.0 (TID 29)
 INFO [2020-01-12 13:33:40,069] ({Executor task launch worker-10} Logging.scala[logInfo]:54) - Running task 1.0 in stage 12.0 (TID 30)
 INFO [2020-01-12 13:33:40,153] ({Executor task launch worker-10} Logging.scala[logInfo]:54) - Times: total = 54, boot = -451, init = 504, finish = 1
 INFO [2020-01-12 13:33:40,164] ({Executor task launch worker-9} Logging.scala[logInfo]:54) - Times: total = 54, boot = -449, init = 503, finish = 0
 INFO [2020-01-12 13:33:40,171] ({Executor task launch worker-10} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 12.0 (TID 30). 2232 bytes result sent to driver
 INFO [2020-01-12 13:33:40,171] ({Executor task launch worker-9} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 12.0 (TID 29). 2232 bytes result sent to driver
 INFO [2020-01-12 13:33:40,183] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 12.0 (TID 30) in 129 ms on localhost (executor driver) (1/2)
 INFO [2020-01-12 13:33:40,184] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 12.0 (TID 29) in 139 ms on localhost (executor driver) (2/2)
 INFO [2020-01-12 13:33:40,190] ({task-result-getter-2} Logging.scala[logInfo]:54) - Removed TaskSet 12.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:33:40,203] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 12 (collect at <stdin>:13) finished in 0.158 s
 INFO [2020-01-12 13:33:40,205] ({Thread-27} Logging.scala[logInfo]:54) - Job 12 finished: collect at <stdin>:13, took 0.424822 s
 INFO [2020-01-12 13:33:40,262] ({pool-2-thread-4} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578836017527 finished by scheduler interpreter_1602312349
 INFO [2020-01-12 13:36:14,565] ({pool-2-thread-12} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578836174560 started by scheduler interpreter_1602312349
 INFO [2020-01-12 13:36:14,624] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Removed broadcast_12_piece0 on 172.18.0.2:34393 in memory (size: 2.4 KB, free: 413.9 MB)
 INFO [2020-01-12 13:36:14,709] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_11_piece0 on 172.18.0.2:34393 in memory (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 13:36:14,719] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Removed broadcast_10_piece0 on 172.18.0.2:34393 in memory (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 13:36:14,740] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Removed broadcast_9_piece0 on 172.18.0.2:34393 in memory (size: 3.2 KB, free: 413.9 MB)
 INFO [2020-01-12 13:36:14,758] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_8_piece0 on 172.18.0.2:34393 in memory (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 13:36:14,775] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_7_piece0 on 172.18.0.2:34393 in memory (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 13:36:14,791] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Removed broadcast_6_piece0 on 172.18.0.2:34393 in memory (size: 2.9 KB, free: 413.9 MB)
 INFO [2020-01-12 13:36:14,804] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_5_piece0 on 172.18.0.2:34393 in memory (size: 2.9 KB, free: 413.9 MB)
 INFO [2020-01-12 13:36:14,909] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: zipWithIndex at <stdin>:11
 INFO [2020-01-12 13:36:14,917] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 13 (zipWithIndex at <stdin>:11) with 2 output partitions
 INFO [2020-01-12 13:36:14,918] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 13 (zipWithIndex at <stdin>:11)
 INFO [2020-01-12 13:36:14,919] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:36:14,920] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:36:14,922] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 13 (PythonRDD[45] at zipWithIndex at <stdin>:11), which has no missing parents
 INFO [2020-01-12 13:36:14,934] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_13 stored as values in memory (estimated size 3.8 KB, free 413.9 MB)
 INFO [2020-01-12 13:36:15,205] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_13_piece0 stored as bytes in memory (estimated size 2.5 KB, free 413.9 MB)
 INFO [2020-01-12 13:36:15,211] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Added broadcast_13_piece0 in memory on 172.18.0.2:34393 (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 13:36:15,220] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 13 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:36:15,220] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 2 missing tasks from ResultStage 13 (PythonRDD[45] at zipWithIndex at <stdin>:11)
 INFO [2020-01-12 13:36:15,221] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 13.0 with 2 tasks
 INFO [2020-01-12 13:36:15,227] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_13.0 tasks to pool default
 INFO [2020-01-12 13:36:15,239] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 13.0 (TID 31, localhost, executor driver, partition 0, PROCESS_LOCAL, 6470 bytes)
 INFO [2020-01-12 13:36:15,260] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 13.0 (TID 32, localhost, executor driver, partition 1, PROCESS_LOCAL, 6470 bytes)
 INFO [2020-01-12 13:36:15,270] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Running task 1.0 in stage 13.0 (TID 32)
 INFO [2020-01-12 13:36:15,276] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Running task 0.0 in stage 13.0 (TID 31)
 INFO [2020-01-12 13:36:15,851] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Times: total = 540, boot = 236, init = 262, finish = 42
 INFO [2020-01-12 13:36:15,851] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Times: total = 522, boot = 217, init = 263, finish = 42
 INFO [2020-01-12 13:36:15,853] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 13.0 (TID 31). 1571 bytes result sent to driver
 INFO [2020-01-12 13:36:15,855] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 13.0 (TID 32). 1571 bytes result sent to driver
 INFO [2020-01-12 13:36:15,856] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 13.0 (TID 31) in 627 ms on localhost (executor driver) (1/2)
 INFO [2020-01-12 13:36:15,857] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 13.0 (TID 32) in 614 ms on localhost (executor driver) (2/2)
 INFO [2020-01-12 13:36:15,857] ({task-result-getter-3} Logging.scala[logInfo]:54) - Removed TaskSet 13.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:36:15,885] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 13 (zipWithIndex at <stdin>:11) finished in 0.657 s
 INFO [2020-01-12 13:36:15,886] ({Thread-27} Logging.scala[logInfo]:54) - Job 13 finished: zipWithIndex at <stdin>:11, took 0.974798 s
 INFO [2020-01-12 13:36:15,993] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: zipWithIndex at <stdin>:12
 INFO [2020-01-12 13:36:15,997] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 14 (zipWithIndex at <stdin>:12) with 2 output partitions
 INFO [2020-01-12 13:36:15,998] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 14 (zipWithIndex at <stdin>:12)
 INFO [2020-01-12 13:36:16,000] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:36:16,001] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:36:16,003] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 14 (PythonRDD[47] at zipWithIndex at <stdin>:12), which has no missing parents
 INFO [2020-01-12 13:36:16,030] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_14 stored as values in memory (estimated size 3.8 KB, free 413.9 MB)
 INFO [2020-01-12 13:36:16,055] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_14_piece0 stored as bytes in memory (estimated size 2.5 KB, free 413.9 MB)
 INFO [2020-01-12 13:36:16,058] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Added broadcast_14_piece0 in memory on 172.18.0.2:34393 (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 13:36:16,068] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 14 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:36:16,069] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 2 missing tasks from ResultStage 14 (PythonRDD[47] at zipWithIndex at <stdin>:12)
 INFO [2020-01-12 13:36:16,070] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 14.0 with 2 tasks
 INFO [2020-01-12 13:36:16,073] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_14.0 tasks to pool default
 INFO [2020-01-12 13:36:16,084] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 14.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 6428 bytes)
 INFO [2020-01-12 13:36:16,090] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 14.0 (TID 34, localhost, executor driver, partition 1, PROCESS_LOCAL, 6428 bytes)
 INFO [2020-01-12 13:36:16,090] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Running task 1.0 in stage 14.0 (TID 34)
 INFO [2020-01-12 13:36:16,100] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Running task 0.0 in stage 14.0 (TID 33)
 INFO [2020-01-12 13:36:17,405] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Times: total = 1311, boot = 1306, init = 1, finish = 4
 INFO [2020-01-12 13:36:17,405] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Times: total = 1288, boot = 1283, init = 1, finish = 4
 INFO [2020-01-12 13:36:17,410] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 14.0 (TID 34). 1571 bytes result sent to driver
 INFO [2020-01-12 13:36:17,411] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 14.0 (TID 33). 1571 bytes result sent to driver
 INFO [2020-01-12 13:36:17,413] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 14.0 (TID 34) in 1328 ms on localhost (executor driver) (1/2)
 INFO [2020-01-12 13:36:17,421] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 14.0 (TID 33) in 1346 ms on localhost (executor driver) (2/2)
 INFO [2020-01-12 13:36:17,422] ({task-result-getter-2} Logging.scala[logInfo]:54) - Removed TaskSet 14.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:36:17,451] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 14 (zipWithIndex at <stdin>:12) finished in 1.377 s
 INFO [2020-01-12 13:36:17,452] ({Thread-27} Logging.scala[logInfo]:54) - Job 14 finished: zipWithIndex at <stdin>:12, took 1.458835 s
 INFO [2020-01-12 13:36:17,492] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: collect at <stdin>:13
 INFO [2020-01-12 13:36:17,493] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 15 (collect at <stdin>:13) with 2 output partitions
 INFO [2020-01-12 13:36:17,493] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 15 (collect at <stdin>:13)
 INFO [2020-01-12 13:36:17,493] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:36:17,493] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:36:17,494] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 15 (PythonRDD[48] at collect at <stdin>:13), which has no missing parents
 INFO [2020-01-12 13:36:17,503] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_15 stored as values in memory (estimated size 3.6 KB, free 413.9 MB)
 INFO [2020-01-12 13:36:17,641] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_15_piece0 stored as bytes in memory (estimated size 2.4 KB, free 413.9 MB)
 INFO [2020-01-12 13:36:17,643] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Added broadcast_15_piece0 in memory on 172.18.0.2:34393 (size: 2.4 KB, free: 413.9 MB)
 INFO [2020-01-12 13:36:17,645] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 15 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:36:17,646] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 2 missing tasks from ResultStage 15 (PythonRDD[48] at collect at <stdin>:13)
 INFO [2020-01-12 13:36:17,646] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 15.0 with 2 tasks
 INFO [2020-01-12 13:36:17,650] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_15.0 tasks to pool default
 INFO [2020-01-12 13:36:17,659] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 15.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 6465 bytes)
 INFO [2020-01-12 13:36:17,661] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 15.0 (TID 36, localhost, executor driver, partition 1, PROCESS_LOCAL, 6465 bytes)
 INFO [2020-01-12 13:36:17,662] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Running task 0.0 in stage 15.0 (TID 35)
 INFO [2020-01-12 13:36:17,667] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Running task 1.0 in stage 15.0 (TID 36)
 INFO [2020-01-12 13:36:17,698] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Times: total = 18, boot = -235, init = 245, finish = 8
 INFO [2020-01-12 13:36:17,700] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Times: total = 24, boot = -243, init = 255, finish = 12
 INFO [2020-01-12 13:36:17,711] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 15.0 (TID 36). 2145 bytes result sent to driver
 INFO [2020-01-12 13:36:17,725] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 15.0 (TID 36) in 65 ms on localhost (executor driver) (1/2)
 INFO [2020-01-12 13:36:17,732] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 15.0 (TID 35). 2232 bytes result sent to driver
 INFO [2020-01-12 13:36:17,775] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 15.0 (TID 35) in 122 ms on localhost (executor driver) (2/2)
 INFO [2020-01-12 13:36:17,775] ({task-result-getter-3} Logging.scala[logInfo]:54) - Removed TaskSet 15.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:36:17,806] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 15 (collect at <stdin>:13) finished in 0.155 s
 INFO [2020-01-12 13:36:17,808] ({Thread-27} Logging.scala[logInfo]:54) - Job 15 finished: collect at <stdin>:13, took 0.315477 s
 INFO [2020-01-12 13:36:17,836] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: collect at <stdin>:15
 INFO [2020-01-12 13:36:17,837] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 16 (collect at <stdin>:15) with 4 output partitions
 INFO [2020-01-12 13:36:17,838] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 16 (collect at <stdin>:15)
 INFO [2020-01-12 13:36:17,838] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:36:17,838] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:36:17,839] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 16 (CartesianRDD[49] at cartesian at NativeMethodAccessorImpl.java:0), which has no missing parents
 INFO [2020-01-12 13:36:17,843] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_16 stored as values in memory (estimated size 3.9 KB, free 413.9 MB)
 INFO [2020-01-12 13:36:17,922] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_16_piece0 stored as bytes in memory (estimated size 2.5 KB, free 413.9 MB)
 INFO [2020-01-12 13:36:17,924] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Added broadcast_16_piece0 in memory on 172.18.0.2:34393 (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 13:36:17,927] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 16 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:36:17,927] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 4 missing tasks from ResultStage 16 (CartesianRDD[49] at cartesian at NativeMethodAccessorImpl.java:0)
 INFO [2020-01-12 13:36:17,928] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 16.0 with 4 tasks
 INFO [2020-01-12 13:36:17,929] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_16.0 tasks to pool default
 INFO [2020-01-12 13:36:17,932] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 16.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 6669 bytes)
 INFO [2020-01-12 13:36:17,934] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 16.0 (TID 38, localhost, executor driver, partition 1, PROCESS_LOCAL, 6922 bytes)
 INFO [2020-01-12 13:36:17,940] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Running task 1.0 in stage 16.0 (TID 38)
 INFO [2020-01-12 13:36:17,940] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Running task 0.0 in stage 16.0 (TID 37)
 INFO [2020-01-12 13:36:18,049] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Times: total = 26, boot = 6, init = 18, finish = 2
 INFO [2020-01-12 13:36:18,070] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Times: total = 29, boot = 9, init = 19, finish = 1
 INFO [2020-01-12 13:36:18,155] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Times: total = 104, boot = 103, init = 1, finish = 0
 INFO [2020-01-12 13:36:18,156] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Times: total = 62, boot = -229, init = 290, finish = 1
 INFO [2020-01-12 13:36:18,173] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Times: total = 101, boot = 50, init = 50, finish = 1
 INFO [2020-01-12 13:36:18,174] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Times: total = 52, boot = -278, init = 329, finish = 1
 INFO [2020-01-12 13:36:18,327] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Times: total = 66, boot = 36, init = 30, finish = 0
 INFO [2020-01-12 13:36:18,375] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 16.0 (TID 37). 4080 bytes result sent to driver
 INFO [2020-01-12 13:36:18,384] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 2.0 in stage 16.0 (TID 39, localhost, executor driver, partition 2, PROCESS_LOCAL, 6922 bytes)
 INFO [2020-01-12 13:36:18,388] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Running task 2.0 in stage 16.0 (TID 39)
 INFO [2020-01-12 13:36:18,392] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 16.0 (TID 37) in 457 ms on localhost (executor driver) (1/4)
 INFO [2020-01-12 13:36:18,418] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Times: total = 228, boot = -136, init = 364, finish = 0
 INFO [2020-01-12 13:36:18,420] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 16.0 (TID 38). 4080 bytes result sent to driver
 INFO [2020-01-12 13:36:18,436] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 3.0 in stage 16.0 (TID 40, localhost, executor driver, partition 3, PROCESS_LOCAL, 6669 bytes)
 INFO [2020-01-12 13:36:18,437] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Running task 3.0 in stage 16.0 (TID 40)
 INFO [2020-01-12 13:36:18,437] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 16.0 (TID 38) in 504 ms on localhost (executor driver) (2/4)
 INFO [2020-01-12 13:36:18,572] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Times: total = 70, boot = -264, init = 333, finish = 1
 INFO [2020-01-12 13:36:18,617] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Times: total = 72, boot = -90, init = 159, finish = 3
 INFO [2020-01-12 13:36:18,633] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Times: total = 59, boot = 15, init = 43, finish = 1
 INFO [2020-01-12 13:36:18,633] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Times: total = 67, boot = -235, init = 301, finish = 1
 INFO [2020-01-12 13:36:18,674] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Times: total = 54, boot = 27, init = 27, finish = 0
 INFO [2020-01-12 13:36:18,676] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Times: total = 64, boot = -417, init = 481, finish = 0
 INFO [2020-01-12 13:36:18,692] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Times: total = 58, boot = 17, init = 40, finish = 1
 INFO [2020-01-12 13:36:18,700] ({Executor task launch worker-12} Logging.scala[logInfo]:54) - Finished task 2.0 in stage 16.0 (TID 39). 4080 bytes result sent to driver
 INFO [2020-01-12 13:36:18,703] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 2.0 in stage 16.0 (TID 39) in 322 ms on localhost (executor driver) (3/4)
 INFO [2020-01-12 13:36:18,733] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Times: total = 55, boot = -159, init = 213, finish = 1
 INFO [2020-01-12 13:36:18,742] ({Executor task launch worker-11} Logging.scala[logInfo]:54) - Finished task 3.0 in stage 16.0 (TID 40). 4167 bytes result sent to driver
 INFO [2020-01-12 13:36:18,744] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 3.0 in stage 16.0 (TID 40) in 321 ms on localhost (executor driver) (4/4)
 INFO [2020-01-12 13:36:18,744] ({task-result-getter-3} Logging.scala[logInfo]:54) - Removed TaskSet 16.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:36:18,753] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 16 (collect at <stdin>:15) finished in 0.822 s
 INFO [2020-01-12 13:36:18,753] ({Thread-27} Logging.scala[logInfo]:54) - Job 16 finished: collect at <stdin>:15, took 0.916872 s
 INFO [2020-01-12 13:36:18,940] ({pool-2-thread-12} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578836174560 finished by scheduler interpreter_1602312349
 INFO [2020-01-12 13:37:42,781] ({pool-2-thread-21} SchedulerFactory.java[jobStarted]:131) - Job remoteInterpretJob_1578836262775 started by scheduler interpreter_1602312349
 INFO [2020-01-12 13:37:43,058] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: zipWithIndex at <stdin>:11
 INFO [2020-01-12 13:37:43,064] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 17 (zipWithIndex at <stdin>:11) with 2 output partitions
 INFO [2020-01-12 13:37:43,064] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 17 (zipWithIndex at <stdin>:11)
 INFO [2020-01-12 13:37:43,064] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:37:43,065] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:37:43,068] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 17 (PythonRDD[51] at zipWithIndex at <stdin>:11), which has no missing parents
 INFO [2020-01-12 13:37:43,074] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_17 stored as values in memory (estimated size 3.8 KB, free 413.9 MB)
 INFO [2020-01-12 13:37:43,145] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.5 KB, free 413.9 MB)
 INFO [2020-01-12 13:37:43,147] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Added broadcast_17_piece0 in memory on 172.18.0.2:34393 (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 13:37:43,149] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 17 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:37:43,151] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 2 missing tasks from ResultStage 17 (PythonRDD[51] at zipWithIndex at <stdin>:11)
 INFO [2020-01-12 13:37:43,152] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 17.0 with 2 tasks
 INFO [2020-01-12 13:37:43,155] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_17.0 tasks to pool default
 INFO [2020-01-12 13:37:43,166] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 17.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 6470 bytes)
 INFO [2020-01-12 13:37:43,169] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 17.0 (TID 42, localhost, executor driver, partition 1, PROCESS_LOCAL, 6470 bytes)
 INFO [2020-01-12 13:37:43,174] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Running task 0.0 in stage 17.0 (TID 41)
 INFO [2020-01-12 13:37:43,179] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Running task 1.0 in stage 17.0 (TID 42)
 INFO [2020-01-12 13:37:43,224] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Times: total = 33, boot = 15, init = 16, finish = 2
 INFO [2020-01-12 13:37:43,263] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 17.0 (TID 42). 1571 bytes result sent to driver
 INFO [2020-01-12 13:37:43,272] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Times: total = 60, boot = 13, init = 45, finish = 2
 INFO [2020-01-12 13:37:43,293] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 17.0 (TID 42) in 126 ms on localhost (executor driver) (1/2)
 INFO [2020-01-12 13:37:43,335] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 17.0 (TID 41). 1658 bytes result sent to driver
 INFO [2020-01-12 13:37:43,348] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 17.0 (TID 41) in 190 ms on localhost (executor driver) (2/2)
 INFO [2020-01-12 13:37:43,358] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 17 (zipWithIndex at <stdin>:11) finished in 0.200 s
 INFO [2020-01-12 13:37:43,360] ({Thread-27} Logging.scala[logInfo]:54) - Job 17 finished: zipWithIndex at <stdin>:11, took 0.299644 s
 INFO [2020-01-12 13:37:43,367] ({task-result-getter-2} Logging.scala[logInfo]:54) - Removed TaskSet 17.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:37:43,484] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: zipWithIndex at <stdin>:12
 INFO [2020-01-12 13:37:43,486] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 18 (zipWithIndex at <stdin>:12) with 2 output partitions
 INFO [2020-01-12 13:37:43,487] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 18 (zipWithIndex at <stdin>:12)
 INFO [2020-01-12 13:37:43,487] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:37:43,487] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:37:43,490] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 18 (PythonRDD[53] at zipWithIndex at <stdin>:12), which has no missing parents
 INFO [2020-01-12 13:37:43,496] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_18 stored as values in memory (estimated size 3.8 KB, free 413.9 MB)
 INFO [2020-01-12 13:37:43,508] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_18_piece0 stored as bytes in memory (estimated size 2.5 KB, free 413.9 MB)
 INFO [2020-01-12 13:37:43,510] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Added broadcast_18_piece0 in memory on 172.18.0.2:34393 (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 13:37:43,524] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 18 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:37:43,529] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 2 missing tasks from ResultStage 18 (PythonRDD[53] at zipWithIndex at <stdin>:12)
 INFO [2020-01-12 13:37:43,530] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 18.0 with 2 tasks
 INFO [2020-01-12 13:37:43,533] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_18.0 tasks to pool default
 INFO [2020-01-12 13:37:43,538] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 18.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 6428 bytes)
 INFO [2020-01-12 13:37:43,567] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 18.0 (TID 44, localhost, executor driver, partition 1, PROCESS_LOCAL, 6428 bytes)
 INFO [2020-01-12 13:37:43,568] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Running task 1.0 in stage 18.0 (TID 44)
 INFO [2020-01-12 13:37:43,571] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Running task 0.0 in stage 18.0 (TID 43)
 INFO [2020-01-12 13:37:43,634] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Times: total = 59, boot = -186, init = 244, finish = 1
 INFO [2020-01-12 13:37:43,636] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 18.0 (TID 44). 1571 bytes result sent to driver
 INFO [2020-01-12 13:37:43,638] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 18.0 (TID 44) in 99 ms on localhost (executor driver) (1/2)
 INFO [2020-01-12 13:37:43,682] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Times: total = 64, boot = -203, init = 267, finish = 0
 INFO [2020-01-12 13:37:43,704] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 18.0 (TID 43). 1658 bytes result sent to driver
 INFO [2020-01-12 13:37:43,706] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 18.0 (TID 43) in 170 ms on localhost (executor driver) (2/2)
 INFO [2020-01-12 13:37:43,706] ({task-result-getter-3} Logging.scala[logInfo]:54) - Removed TaskSet 18.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:37:43,821] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 18 (zipWithIndex at <stdin>:12) finished in 0.285 s
 INFO [2020-01-12 13:37:43,824] ({Thread-27} Logging.scala[logInfo]:54) - Job 18 finished: zipWithIndex at <stdin>:12, took 0.339719 s
 INFO [2020-01-12 13:37:43,914] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: collect at <stdin>:13
 INFO [2020-01-12 13:37:43,918] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 19 (collect at <stdin>:13) with 2 output partitions
 INFO [2020-01-12 13:37:43,919] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 19 (collect at <stdin>:13)
 INFO [2020-01-12 13:37:43,919] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:37:43,920] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:37:43,931] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 19 (PythonRDD[54] at collect at <stdin>:13), which has no missing parents
 INFO [2020-01-12 13:37:43,953] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_19 stored as values in memory (estimated size 3.6 KB, free 413.9 MB)
 INFO [2020-01-12 13:37:44,022] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.4 KB, free 413.9 MB)
 INFO [2020-01-12 13:37:44,024] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Added broadcast_19_piece0 in memory on 172.18.0.2:34393 (size: 2.4 KB, free: 413.9 MB)
 INFO [2020-01-12 13:37:44,026] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 19 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:37:44,028] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 2 missing tasks from ResultStage 19 (PythonRDD[54] at collect at <stdin>:13)
 INFO [2020-01-12 13:37:44,028] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 19.0 with 2 tasks
 INFO [2020-01-12 13:37:44,038] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_19.0 tasks to pool default
 INFO [2020-01-12 13:37:44,043] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 19.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 6465 bytes)
 INFO [2020-01-12 13:37:44,046] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 19.0 (TID 46, localhost, executor driver, partition 1, PROCESS_LOCAL, 6465 bytes)
 INFO [2020-01-12 13:37:44,050] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Running task 1.0 in stage 19.0 (TID 46)
 INFO [2020-01-12 13:37:44,053] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Running task 0.0 in stage 19.0 (TID 45)
 INFO [2020-01-12 13:37:44,112] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Times: total = 48, boot = -392, init = 439, finish = 1
 INFO [2020-01-12 13:37:44,118] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 19.0 (TID 46). 2145 bytes result sent to driver
 INFO [2020-01-12 13:37:44,125] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 19.0 (TID 46) in 81 ms on localhost (executor driver) (1/2)
 INFO [2020-01-12 13:37:44,134] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Times: total = 76, boot = -351, init = 426, finish = 1
 INFO [2020-01-12 13:37:44,139] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 19.0 (TID 45). 2145 bytes result sent to driver
 INFO [2020-01-12 13:37:44,146] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 19.0 (TID 45) in 105 ms on localhost (executor driver) (2/2)
 INFO [2020-01-12 13:37:44,150] ({task-result-getter-2} Logging.scala[logInfo]:54) - Removed TaskSet 19.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:37:44,147] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 19 (collect at <stdin>:13) finished in 0.100 s
 INFO [2020-01-12 13:37:44,151] ({Thread-27} Logging.scala[logInfo]:54) - Job 19 finished: collect at <stdin>:13, took 0.236543 s
 INFO [2020-01-12 13:37:44,461] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: collect at <stdin>:15
 INFO [2020-01-12 13:37:44,462] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 20 (collect at <stdin>:15) with 4 output partitions
 INFO [2020-01-12 13:37:44,463] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 20 (collect at <stdin>:15)
 INFO [2020-01-12 13:37:44,463] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:37:44,463] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:37:44,464] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 20 (CartesianRDD[55] at cartesian at NativeMethodAccessorImpl.java:0), which has no missing parents
 INFO [2020-01-12 13:37:44,471] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_20 stored as values in memory (estimated size 3.9 KB, free 413.9 MB)
 INFO [2020-01-12 13:37:44,699] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_20_piece0 stored as bytes in memory (estimated size 2.5 KB, free 413.9 MB)
 INFO [2020-01-12 13:37:44,704] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Added broadcast_20_piece0 in memory on 172.18.0.2:34393 (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 13:37:44,706] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 20 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:37:44,706] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 4 missing tasks from ResultStage 20 (CartesianRDD[55] at cartesian at NativeMethodAccessorImpl.java:0)
 INFO [2020-01-12 13:37:44,707] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 20.0 with 4 tasks
 INFO [2020-01-12 13:37:44,709] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_20.0 tasks to pool default
 INFO [2020-01-12 13:37:44,724] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 20.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 6670 bytes)
 INFO [2020-01-12 13:37:44,726] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 20.0 (TID 48, localhost, executor driver, partition 1, PROCESS_LOCAL, 6923 bytes)
 INFO [2020-01-12 13:37:44,736] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Running task 1.0 in stage 20.0 (TID 48)
 INFO [2020-01-12 13:37:44,740] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Running task 0.0 in stage 20.0 (TID 47)
 INFO [2020-01-12 13:37:44,847] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Times: total = 22, boot = 5, init = 13, finish = 4
 INFO [2020-01-12 13:37:44,915] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Times: total = 58, boot = 38, init = 18, finish = 2
 INFO [2020-01-12 13:37:44,942] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Times: total = 58, boot = 0, init = 57, finish = 1
 INFO [2020-01-12 13:37:44,944] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Times: total = 45, boot = -605, init = 649, finish = 1
 INFO [2020-01-12 13:37:44,972] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Times: total = 57, boot = 26, init = 30, finish = 1
 INFO [2020-01-12 13:37:44,972] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Times: total = 47, boot = -608, init = 654, finish = 1
 INFO [2020-01-12 13:37:45,001] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Times: total = 47, boot = 3, init = 44, finish = 0
 INFO [2020-01-12 13:37:45,003] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 20.0 (TID 48). 4080 bytes result sent to driver
 INFO [2020-01-12 13:37:45,006] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 2.0 in stage 20.0 (TID 49, localhost, executor driver, partition 2, PROCESS_LOCAL, 6923 bytes)
 INFO [2020-01-12 13:37:45,007] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 20.0 (TID 48) in 282 ms on localhost (executor driver) (1/4)
 INFO [2020-01-12 13:37:45,011] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Running task 2.0 in stage 20.0 (TID 49)
 INFO [2020-01-12 13:37:45,088] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Times: total = 49, boot = -139, init = 187, finish = 1
 INFO [2020-01-12 13:37:45,093] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 20.0 (TID 47). 4080 bytes result sent to driver
 INFO [2020-01-12 13:37:45,095] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 3.0 in stage 20.0 (TID 50, localhost, executor driver, partition 3, PROCESS_LOCAL, 6670 bytes)
 INFO [2020-01-12 13:37:45,097] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Running task 3.0 in stage 20.0 (TID 50)
 INFO [2020-01-12 13:37:45,098] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 20.0 (TID 47) in 377 ms on localhost (executor driver) (2/4)
 INFO [2020-01-12 13:37:45,151] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Times: total = 59, boot = -217, init = 275, finish = 1
 INFO [2020-01-12 13:37:45,212] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Times: total = 56, boot = 1, init = 54, finish = 1
 INFO [2020-01-12 13:37:45,231] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Times: total = 70, boot = -115, init = 184, finish = 1
 INFO [2020-01-12 13:37:45,232] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Times: total = 48, boot = -27, init = 74, finish = 1
 INFO [2020-01-12 13:37:45,286] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Times: total = 69, boot = 7, init = 61, finish = 1
 INFO [2020-01-12 13:37:45,287] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Times: total = 53, boot = -97, init = 149, finish = 1
 INFO [2020-01-12 13:37:45,292] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Times: total = 60, boot = 4, init = 55, finish = 1
 INFO [2020-01-12 13:37:45,304] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Finished task 2.0 in stage 20.0 (TID 49). 4080 bytes result sent to driver
 INFO [2020-01-12 13:37:45,308] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 2.0 in stage 20.0 (TID 49) in 303 ms on localhost (executor driver) (3/4)
 INFO [2020-01-12 13:37:45,351] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Times: total = 55, boot = -217, init = 272, finish = 0
 INFO [2020-01-12 13:37:45,352] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Finished task 3.0 in stage 20.0 (TID 50). 4080 bytes result sent to driver
 INFO [2020-01-12 13:37:45,355] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 3.0 in stage 20.0 (TID 50) in 260 ms on localhost (executor driver) (4/4)
 INFO [2020-01-12 13:37:45,356] ({task-result-getter-2} Logging.scala[logInfo]:54) - Removed TaskSet 20.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:37:45,360] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 20 (collect at <stdin>:15) finished in 0.638 s
 INFO [2020-01-12 13:37:45,361] ({Thread-27} Logging.scala[logInfo]:54) - Job 20 finished: collect at <stdin>:15, took 0.899340 s
 INFO [2020-01-12 13:37:45,789] ({Thread-27} Logging.scala[logInfo]:54) - Starting job: collect at <stdin>:17
 INFO [2020-01-12 13:37:45,794] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Got job 21 (collect at <stdin>:17) with 4 output partitions
 INFO [2020-01-12 13:37:45,795] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Final stage: ResultStage 21 (collect at <stdin>:17)
 INFO [2020-01-12 13:37:45,795] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Parents of final stage: List()
 INFO [2020-01-12 13:37:45,796] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Missing parents: List()
 INFO [2020-01-12 13:37:45,796] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting ResultStage 21 (PythonRDD[56] at collect at <stdin>:17), which has no missing parents
 INFO [2020-01-12 13:37:45,803] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_21 stored as values in memory (estimated size 5.1 KB, free 413.9 MB)
 INFO [2020-01-12 13:37:45,907] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.2 KB, free 413.9 MB)
 INFO [2020-01-12 13:37:45,914] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Added broadcast_21_piece0 in memory on 172.18.0.2:34393 (size: 3.2 KB, free: 413.9 MB)
 INFO [2020-01-12 13:37:45,915] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Created broadcast 21 from broadcast at DAGScheduler.scala:996
 INFO [2020-01-12 13:37:45,915] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Submitting 4 missing tasks from ResultStage 21 (PythonRDD[56] at collect at <stdin>:17)
 INFO [2020-01-12 13:37:45,916] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Adding task set 21.0 with 4 tasks
 INFO [2020-01-12 13:37:45,917] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - Added task set TaskSet_21.0 tasks to pool default
 INFO [2020-01-12 13:37:45,919] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 0.0 in stage 21.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 6670 bytes)
 INFO [2020-01-12 13:37:45,920] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Starting task 1.0 in stage 21.0 (TID 52, localhost, executor driver, partition 1, PROCESS_LOCAL, 6923 bytes)
 INFO [2020-01-12 13:37:45,921] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Running task 0.0 in stage 21.0 (TID 51)
 INFO [2020-01-12 13:37:45,921] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Running task 1.0 in stage 21.0 (TID 52)
 INFO [2020-01-12 13:37:46,014] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 12, boot = 4, init = 7, finish = 1
 INFO [2020-01-12 13:37:46,025] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 30, boot = 9, init = 20, finish = 1
 INFO [2020-01-12 13:37:46,062] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 48, boot = 25, init = 22, finish = 1
 INFO [2020-01-12 13:37:46,063] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 47, boot = -743, init = 790, finish = 0
 INFO [2020-01-12 13:37:46,103] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 76, boot = 28, init = 48, finish = 0
 INFO [2020-01-12 13:37:46,103] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 59, boot = -625, init = 683, finish = 1
 INFO [2020-01-12 13:37:46,112] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 49, boot = 8, init = 40, finish = 1
 INFO [2020-01-12 13:37:46,138] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Times: total = 166, boot = -666, init = 820, finish = 12
 INFO [2020-01-12 13:37:46,140] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 21.0 (TID 51). 2611 bytes result sent to driver
 INFO [2020-01-12 13:37:46,142] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 2.0 in stage 21.0 (TID 53, localhost, executor driver, partition 2, PROCESS_LOCAL, 6923 bytes)
 INFO [2020-01-12 13:37:46,142] ({task-result-getter-1} Logging.scala[logInfo]:54) - Finished task 0.0 in stage 21.0 (TID 51) in 224 ms on localhost (executor driver) (1/4)
 INFO [2020-01-12 13:37:46,143] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Running task 2.0 in stage 21.0 (TID 53)
 INFO [2020-01-12 13:37:46,172] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 59, boot = -119, init = 178, finish = 0
 INFO [2020-01-12 13:37:46,176] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Times: total = 193, boot = -626, init = 817, finish = 2
 INFO [2020-01-12 13:37:46,177] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 21.0 (TID 52). 2611 bytes result sent to driver
 INFO [2020-01-12 13:37:46,183] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Starting task 3.0 in stage 21.0 (TID 54, localhost, executor driver, partition 3, PROCESS_LOCAL, 6670 bytes)
 INFO [2020-01-12 13:37:46,184] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Running task 3.0 in stage 21.0 (TID 54)
 INFO [2020-01-12 13:37:46,187] ({task-result-getter-3} Logging.scala[logInfo]:54) - Finished task 1.0 in stage 21.0 (TID 52) in 265 ms on localhost (executor driver) (2/4)
 INFO [2020-01-12 13:37:46,273] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 50, boot = -69, init = 119, finish = 0
 INFO [2020-01-12 13:37:46,333] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 65, boot = -67, init = 131, finish = 1
 INFO [2020-01-12 13:37:46,334] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 50, boot = 12, init = 37, finish = 1
 INFO [2020-01-12 13:37:46,334] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 57, boot = -35, init = 91, finish = 1
 INFO [2020-01-12 13:37:46,383] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 49, boot = 16, init = 33, finish = 0
 INFO [2020-01-12 13:37:46,384] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 54, boot = -196, init = 249, finish = 1
 INFO [2020-01-12 13:37:46,414] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 78, boot = 6, init = 71, finish = 1
 INFO [2020-01-12 13:37:46,419] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Times: total = 207, boot = -87, init = 291, finish = 3
 INFO [2020-01-12 13:37:46,421] ({Executor task launch worker-13} Logging.scala[logInfo]:54) - Finished task 2.0 in stage 21.0 (TID 53). 2611 bytes result sent to driver
 INFO [2020-01-12 13:37:46,426] ({task-result-getter-0} Logging.scala[logInfo]:54) - Finished task 2.0 in stage 21.0 (TID 53) in 284 ms on localhost (executor driver) (3/4)
 INFO [2020-01-12 13:37:46,440] ({stdout writer for python} Logging.scala[logInfo]:54) - Times: total = 47, boot = -164, init = 211, finish = 0
 INFO [2020-01-12 13:37:46,452] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Times: total = 209, boot = -68, init = 274, finish = 3
 INFO [2020-01-12 13:37:46,454] ({Executor task launch worker-14} Logging.scala[logInfo]:54) - Finished task 3.0 in stage 21.0 (TID 54). 2611 bytes result sent to driver
 INFO [2020-01-12 13:37:46,470] ({task-result-getter-2} Logging.scala[logInfo]:54) - Finished task 3.0 in stage 21.0 (TID 54) in 291 ms on localhost (executor driver) (4/4)
 INFO [2020-01-12 13:37:46,471] ({task-result-getter-2} Logging.scala[logInfo]:54) - Removed TaskSet 21.0, whose tasks have all completed, from pool default
 INFO [2020-01-12 13:37:46,476] ({dag-scheduler-event-loop} Logging.scala[logInfo]:54) - ResultStage 21 (collect at <stdin>:17) finished in 0.558 s
 INFO [2020-01-12 13:37:46,479] ({Thread-27} Logging.scala[logInfo]:54) - Job 21 finished: collect at <stdin>:17, took 0.689050 s
 INFO [2020-01-12 13:37:46,505] ({pool-2-thread-21} SchedulerFactory.java[jobFinished]:137) - Job remoteInterpretJob_1578836262775 finished by scheduler interpreter_1602312349
 INFO [2020-01-12 14:05:50,654] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Removed broadcast_21_piece0 on 172.18.0.2:34393 in memory (size: 3.2 KB, free: 413.9 MB)
 INFO [2020-01-12 14:05:50,663] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Removed broadcast_20_piece0 on 172.18.0.2:34393 in memory (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 14:05:50,667] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_19_piece0 on 172.18.0.2:34393 in memory (size: 2.4 KB, free: 413.9 MB)
 INFO [2020-01-12 14:05:50,671] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Removed broadcast_18_piece0 on 172.18.0.2:34393 in memory (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 14:05:50,675] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_17_piece0 on 172.18.0.2:34393 in memory (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 14:05:50,681] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Removed broadcast_16_piece0 on 172.18.0.2:34393 in memory (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 14:05:50,690] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_15_piece0 on 172.18.0.2:34393 in memory (size: 2.4 KB, free: 413.9 MB)
 INFO [2020-01-12 14:05:50,695] ({dispatcher-event-loop-0} Logging.scala[logInfo]:54) - Removed broadcast_14_piece0 on 172.18.0.2:34393 in memory (size: 2.5 KB, free: 413.9 MB)
 INFO [2020-01-12 14:05:50,700] ({dispatcher-event-loop-1} Logging.scala[logInfo]:54) - Removed broadcast_13_piece0 on 172.18.0.2:34393 in memory (size: 2.5 KB, free: 413.9 MB)
