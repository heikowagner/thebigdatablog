{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 13:16:45.615930: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 13:16:49.869189: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-29 13:16:50.168536: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-29 13:16:50.189864: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-29 13:16:50.190169: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-29 13:16:51.664079: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-29 13:16:51.665471: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-29 13:16:51.665510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-12-29 13:16:51.665908: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-29 13:16:51.666312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:0 with 3934 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:0a:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras.utils as ku \n",
    "import pickle\n",
    "\n",
    "print(tf.keras.__version__)\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas\n",
    "#!pip install --timeout=10000 matplotlib\n",
    "#!pip install pydot\n",
    "#!pip install tensorflow-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_spaces(x):\n",
    "    return \" \".join(x)\n",
    "\n",
    "# We load the list, add a space between each letter and add an EOP (End of Passwort) Symbol pp. Since this is the only 2 letter \"word\" the EOP is unique.\n",
    "def transform_password(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df_in[0].dropna().apply(lambda x: add_spaces(x) + ' eof' )\n",
    "    \n",
    "try:\n",
    "    with open('data.pkl', 'rb') as file:\n",
    "        df = pickle.load(file)\n",
    "except:\n",
    "    # Load the Password list into Memory\n",
    "    url = \"https://raw.githubusercontent.com/danielmiessler/SecLists/master/Passwords/Common-Credentials/10-million-password-list-top-1000000.txt\"\n",
    "\n",
    "    df_in = pd.read_csv(url, header=None)\n",
    "\n",
    "    df = transform_password(df_in)\n",
    "    with open('data.pkl', 'wb') as file:\n",
    "        # Cache Data\n",
    "        pickle.dump(df, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We generate the observed sequence and the next word to be predicted (target).\n",
    "# ToDo: Need to exclude last letter\n",
    "sequences = []\n",
    "#target =[]\n",
    "for row in df:#[:20_000]:   #200000\n",
    "    i=-1\n",
    "    row_sequences = []\n",
    "    for letter in row.split():\n",
    "        if i>=0:\n",
    "            if i>0:\n",
    "                row_sequences.append(row_sequences_dummy + [letter] )\n",
    "            row_sequences_dummy = row_sequences_dummy + [letter]\n",
    "            #target.append([letter])\n",
    "        else:\n",
    "            row_sequences_dummy=[letter]\n",
    "        i=i+1\n",
    "    sequences.append(row_sequences)\n",
    "sequences = [num for elem in sequences for num in elem]\n",
    "\n",
    "#This approach may allow the model to use the context of each line to help the model in those cases where a simple one-word-in-and-out model creates ambiguity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#We us a Tokenizer to code each Letter into a number\n",
    "\n",
    "tokenizer  = Tokenizer(filters=None, char_level=True, lower=False)\n",
    "tokenizer.fit_on_texts(sequences)\n",
    "\n",
    "# Translation from Word to Token and back\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = tokenizer.index_word\n",
    "vocab_size = len(word2idx) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The one hot matrix is nice, but we don't need that\n",
    "#1. get max password length\n",
    "\n",
    "max_length = max([len(x) for x in sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_and_tokenize(sequences, tokenizer, max_length):\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences( tokenizer.texts_to_sequences(sequences) , maxlen = max_length, padding='pre')\n",
    "\n",
    "tok_sequence = pad_and_tokenize(sequences, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Data into X and y\n",
    "\n",
    "predictors, label = tok_sequence[:,:-1], tok_sequence[:,-1]\n",
    "label = ku.to_categorical(label, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6529103, 39)\n",
      "(6529103, 96)\n"
     ]
    }
   ],
   "source": [
    "print(predictors.shape)\n",
    "print(label.shape)\n",
    "X_train=predictors\n",
    "y_train=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PasswordBatchGenerator(ku.Sequence) :\n",
    "  \n",
    "  def __init__(self, X_train, labels, batch_size) :\n",
    "    self.X_train = X_train\n",
    "    self.labels = labels\n",
    "    self.batch_size = batch_size\n",
    "    \n",
    "    \n",
    "  def __len__(self) :\n",
    "    return (np.ceil(self.X_train.shape[0] / float(self.batch_size))).astype(np.int32)\n",
    "  \n",
    "  \n",
    "  def __getitem__(self, idx) :\n",
    "    batch_x = self.X_train[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "    \n",
    "    return (batch_x,batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garbage collector\n",
    "try:\n",
    "    del df_in\n",
    "    del sequences\n",
    "    del df\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Init generator\n",
    "batch_size= 10_000\n",
    "training_batch = PasswordBatchGenerator(X_train, y_train, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 13:17:56.661778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-29 13:17:56.662944: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-29 13:17:56.664121: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-29 13:17:56.667116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-29 13:17:56.667761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-29 13:17:56.668363: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-29 13:17:56.669282: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-29 13:17:56.669316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-12-29 13:17:56.669720: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0a:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-29 13:17:56.669776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3934 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:0a:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 13:18:02.980008: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'cond_40/output/_23'\n",
      "2022-12-29 13:18:05.156621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2022-12-29 13:18:07.318494: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fe7a000ffe0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-29 13:18:07.319454: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 SUPER, Compute Capability 7.5\n",
      "2022-12-29 13:18:07.493464: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-12-29 13:18:08.115907: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "653/653 [==============================] - 148s 210ms/step - loss: 3.3018\n",
      "Epoch 2/100\n",
      "653/653 [==============================] - 136s 208ms/step - loss: 2.9517\n",
      "Epoch 3/100\n",
      "653/653 [==============================] - 134s 205ms/step - loss: 2.9078\n",
      "Epoch 4/100\n",
      "653/653 [==============================] - 135s 206ms/step - loss: 2.8801\n",
      "Epoch 5/100\n",
      "653/653 [==============================] - 134s 205ms/step - loss: 2.8561\n",
      "Epoch 6/100\n",
      "653/653 [==============================] - 134s 205ms/step - loss: 2.8315\n",
      "Epoch 7/100\n",
      "653/653 [==============================] - 134s 205ms/step - loss: 2.8085\n",
      "Epoch 8/100\n",
      "653/653 [==============================] - 134s 205ms/step - loss: 2.7899\n",
      "Epoch 9/100\n",
      "653/653 [==============================] - 134s 205ms/step - loss: 2.7717\n",
      "Epoch 10/100\n",
      "653/653 [==============================] - 134s 205ms/step - loss: 2.7577\n",
      "Epoch 11/100\n",
      "653/653 [==============================] - 134s 205ms/step - loss: 2.7449\n",
      "Epoch 12/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.7348\n",
      "Epoch 13/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.7257\n",
      "Epoch 14/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.7186\n",
      "Epoch 15/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.7114\n",
      "Epoch 16/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.7053\n",
      "Epoch 17/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.7008\n",
      "Epoch 18/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6951\n",
      "Epoch 19/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6909\n",
      "Epoch 20/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6866\n",
      "Epoch 21/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6822\n",
      "Epoch 22/100\n",
      "653/653 [==============================] - 135s 207ms/step - loss: 2.6787\n",
      "Epoch 23/100\n",
      "653/653 [==============================] - 134s 206ms/step - loss: 2.6751\n",
      "Epoch 24/100\n",
      "653/653 [==============================] - 135s 206ms/step - loss: 2.6718\n",
      "Epoch 25/100\n",
      "653/653 [==============================] - 135s 207ms/step - loss: 2.6692\n",
      "Epoch 26/100\n",
      "653/653 [==============================] - 135s 206ms/step - loss: 2.6658\n",
      "Epoch 27/100\n",
      "653/653 [==============================] - 135s 206ms/step - loss: 2.6631\n",
      "Epoch 28/100\n",
      "653/653 [==============================] - 135s 207ms/step - loss: 2.6598\n",
      "Epoch 29/100\n",
      "653/653 [==============================] - 135s 207ms/step - loss: 2.6572\n",
      "Epoch 30/100\n",
      "653/653 [==============================] - 134s 206ms/step - loss: 2.6548\n",
      "Epoch 31/100\n",
      "653/653 [==============================] - 135s 207ms/step - loss: 2.6526\n",
      "Epoch 32/100\n",
      "653/653 [==============================] - 134s 206ms/step - loss: 2.6501\n",
      "Epoch 33/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6477\n",
      "Epoch 34/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6459\n",
      "Epoch 35/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6436\n",
      "Epoch 36/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6419\n",
      "Epoch 37/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6404\n",
      "Epoch 38/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6379\n",
      "Epoch 39/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6366\n",
      "Epoch 40/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6343\n",
      "Epoch 41/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6331\n",
      "Epoch 42/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6310\n",
      "Epoch 43/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6299\n",
      "Epoch 44/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6280\n",
      "Epoch 45/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6270\n",
      "Epoch 46/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6256\n",
      "Epoch 47/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6245\n",
      "Epoch 48/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6229\n",
      "Epoch 49/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6217\n",
      "Epoch 50/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6206\n",
      "Epoch 51/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6197\n",
      "Epoch 52/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6179\n",
      "Epoch 53/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6177\n",
      "Epoch 54/100\n",
      "653/653 [==============================] - 132s 203ms/step - loss: 2.6159\n",
      "Epoch 55/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6149\n",
      "Epoch 56/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6142\n",
      "Epoch 57/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6127\n",
      "Epoch 58/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6120\n",
      "Epoch 59/100\n",
      "653/653 [==============================] - 132s 203ms/step - loss: 2.6118\n",
      "Epoch 60/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6103\n",
      "Epoch 61/100\n",
      "653/653 [==============================] - 132s 202ms/step - loss: 2.6090\n",
      "Epoch 62/100\n",
      "653/653 [==============================] - 138s 212ms/step - loss: 2.6087\n",
      "Epoch 63/100\n",
      "653/653 [==============================] - 142s 217ms/step - loss: 2.6077\n",
      "Epoch 64/100\n",
      "653/653 [==============================] - 141s 215ms/step - loss: 2.6069\n",
      "Epoch 65/100\n",
      "653/653 [==============================] - 140s 215ms/step - loss: 2.6060\n",
      "Epoch 66/100\n",
      "653/653 [==============================] - 143s 219ms/step - loss: 2.6053\n",
      "Epoch 67/100\n",
      "653/653 [==============================] - 140s 215ms/step - loss: 2.6046\n",
      "Epoch 68/100\n",
      "653/653 [==============================] - 143s 219ms/step - loss: 2.6036\n",
      "Epoch 69/100\n",
      "653/653 [==============================] - 147s 225ms/step - loss: 2.6027\n",
      "Epoch 70/100\n",
      "653/653 [==============================] - 141s 215ms/step - loss: 2.6026\n",
      "Epoch 71/100\n",
      "653/653 [==============================] - 140s 214ms/step - loss: 2.6015\n",
      "Epoch 72/100\n",
      "653/653 [==============================] - 138s 211ms/step - loss: 2.6005\n",
      "Epoch 73/100\n",
      "653/653 [==============================] - 138s 211ms/step - loss: 2.6005\n",
      "Epoch 74/100\n",
      "653/653 [==============================] - 138s 212ms/step - loss: 2.5997\n",
      "Epoch 75/100\n",
      "653/653 [==============================] - 137s 210ms/step - loss: 2.5991\n",
      "Epoch 76/100\n",
      "653/653 [==============================] - 138s 211ms/step - loss: 2.5979\n",
      "Epoch 77/100\n",
      "653/653 [==============================] - 138s 211ms/step - loss: 2.5978\n",
      "Epoch 78/100\n",
      "653/653 [==============================] - 138s 211ms/step - loss: 2.5970\n",
      "Epoch 79/100\n",
      "653/653 [==============================] - 138s 211ms/step - loss: 2.5963\n",
      "Epoch 80/100\n",
      "653/653 [==============================] - 138s 211ms/step - loss: 2.5958\n",
      "Epoch 81/100\n",
      "653/653 [==============================] - 134s 206ms/step - loss: 2.5953\n",
      "Epoch 82/100\n",
      "653/653 [==============================] - 134s 205ms/step - loss: 2.5949\n",
      "Epoch 83/100\n",
      "653/653 [==============================] - 134s 205ms/step - loss: 2.5943\n",
      "Epoch 84/100\n",
      "653/653 [==============================] - 134s 205ms/step - loss: 2.5937\n",
      "Epoch 85/100\n",
      "653/653 [==============================] - 133s 204ms/step - loss: 2.5932\n",
      "Epoch 86/100\n",
      "653/653 [==============================] - 133s 203ms/step - loss: 2.5926\n",
      "Epoch 87/100\n",
      "653/653 [==============================] - 133s 203ms/step - loss: 2.5924\n",
      "Epoch 88/100\n",
      "653/653 [==============================] - 133s 204ms/step - loss: 2.5916\n",
      "Epoch 89/100\n",
      "653/653 [==============================] - 133s 203ms/step - loss: 2.5912\n",
      "Epoch 90/100\n",
      "653/653 [==============================] - 133s 203ms/step - loss: 2.5906\n",
      "Epoch 91/100\n",
      "653/653 [==============================] - 133s 203ms/step - loss: 2.5903\n",
      "Epoch 92/100\n",
      "653/653 [==============================] - 135s 207ms/step - loss: 2.5896\n",
      "Epoch 93/100\n",
      "653/653 [==============================] - 147s 225ms/step - loss: 2.5893\n",
      "Epoch 94/100\n",
      "653/653 [==============================] - 135s 207ms/step - loss: 2.5889\n",
      "Epoch 95/100\n",
      "653/653 [==============================] - 135s 206ms/step - loss: 2.5883\n",
      "Epoch 96/100\n",
      "653/653 [==============================] - 135s 207ms/step - loss: 2.5872\n",
      "Epoch 97/100\n",
      "653/653 [==============================] - 135s 206ms/step - loss: 2.5870\n",
      "Epoch 98/100\n",
      "653/653 [==============================] - 135s 206ms/step - loss: 2.5873\n",
      "Epoch 99/100\n",
      "653/653 [==============================] - 136s 208ms/step - loss: 2.5865\n",
      "Epoch 100/100\n",
      "653/653 [==============================] - 137s 210ms/step - loss: 2.5859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe8cafd28e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# https://stackoverflow.com/questions/43341374/tensorflow-dynamic-rnn-lstm-how-to-format-input\n",
    "# https://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html\n",
    "# https://medium.com/@shivambansal36/language-modelling-text-generation-using-lstms-deep-learning-for-nlp-ed36b224b275\n",
    "# https://ai.stackexchange.com/questions/18198/what-is-the-difference-between-lstm-and-rnn#:~:text=The%20main%20difference%20between%20an%20LSTM%20unit%20and,better%20the%20flow%20of%20information%20through%20the%20unit.\n",
    "\n",
    "try:\n",
    "  with open('/root/model.pkl', 'rb') as file:\n",
    "      model = pickle.load(file)\n",
    "except:\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, 10, input_length=max_length-1), #Turns positive integers (indexes) into dense vectors of fixed size.\n",
    "    tf.keras.layers.Masking(mask_value=0),\n",
    "    # tf.keras.layers.LSTM(100, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(100), # skips masked timesteps\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
    "  ])\n",
    "  model.compile(\n",
    "    #optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                optimizer='adam')\n",
    "\n",
    "  # model.fit( X_train , y_train, epochs=10, verbose=1, batch_size=10_000)    # I am not sure if my fitting here works, my code does not make it here\n",
    "\n",
    "  # big data needs a generator\n",
    "  model.fit( training_batch , epochs=100, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dropout\n",
      ".........vars\n",
      "......embedding\n",
      ".........vars\n",
      "............0\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......masking\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "metadata.json                                  2022-12-29 17:02:40           64\n",
      "config.json                                    2022-12-29 17:02:40         2454\n",
      "variables.h5                                   2022-12-29 17:02:40       687008\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# pickle model\n",
    "with open('/root/model.pkl', 'wb') as file:\n",
    "    # A new file will be created\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plt_props(vals, preds):\n",
    "    f = plt.figure()\n",
    "    f.set_figwidth(20)\n",
    "    plt.bar(vals, preds, width=0.9)\n",
    "    plt.show()\n",
    "\n",
    "def predict_letter(vocabular:list, propabilities:list, plot:bool=False)->dict:\n",
    "    \"\"\"Performs a random choice out of the vocabular based on the passed propabilities.\"\"\"\n",
    "    if plot:\n",
    "        plt_props(vocabular, propabilities[0])\n",
    "    return np.random.choice( vocabular , 1, p=propabilities[0])[0]\n",
    "\n",
    "def predict_next_letter(previous_letters: str, model: Sequential, tokenizer: Tokenizer, plot:bool=False ) -> str:\n",
    "    max_length = model.get_config()[\"layers\"][0][\"config\"][\"batch_input_shape\"][1]\n",
    "    previous_letters = list(map(add_spaces, [previous_letters]))\n",
    "    tok_prev = pad_and_tokenize(previous_letters, tokenizer, max_length)\n",
    "    propabilities = model.predict(tok_prev)\n",
    "    predicted_letter = predict_letter(['eof'] + list(tokenizer.index_word.values()) , list(propabilities), plot)\n",
    "    return predicted_letter\n",
    "\n",
    "\n",
    "def predict_password(previous_letters: str, model: Sequential, tokenizer: Tokenizer) -> str:\n",
    "    password = previous_letters\n",
    "    new_letter=\"\"\n",
    "    while True:\n",
    "        new_letter = predict_next_letter(password, model, tokenizer)\n",
    "        if new_letter == \"eof\":\n",
    "            break\n",
    "        password = password + new_letter\n",
    "    return password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'FGD620Ku'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_letter(\"FGD\", model, tokenizer, True)\n",
    "\n",
    "predict_password(\"FGD\", model, tokenizer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a benchmark we will train a simple feed foreward newtwork. This Network corresponds to the markov chain approach described here. We use the the current letter as input to try to predict the next letter. Apart from this, the model does not use any sequencial or positional informations. \n",
    "# Next, we need to create sequences of words to train the model with one word as input and one word as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://jhui.github.io/2017/03/15/RNN-LSTM-GRU/\n",
    "#https://www.simplilearn.com/tutorials/deep-learning-tutorial/rnn\n",
    "#https://www.kaggle.com/code/namansood/nlp-guide-next-word-prediction-and-deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3504721098.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[85], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    For what you're asking, I don't think a Bidirectional network would be good. (The reverse direction would be trying to predict something that does not appear at the end, but before the beginning, and I believe you're going to want to take the output and make it an input and keep predicting further, right?)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "For what you're asking, I don't think a Bidirectional network would be good. (The reverse direction would be trying to predict something that does not appear at the end, but before the beginning, and I believe you're going to want to take the output and make it an input and keep predicting further, right?)\n",
    "\n",
    "So, first, remove the Bidirectional from your model, keep only the LSTM.\n",
    "\n",
    "Keras recurrent layers may output only the last step, or, if you set return_sequences=True, output all steps.\n",
    "\n",
    "So, the trick is adjusting both the data and the model like this:\n",
    "\n",
    "    In the LSTM layers, add return_sequences=True. (Your output will be entire sentences)\n",
    "    Make Y be entire sentences one step ahead of X: X,y = sequences[:,:-1], sequences[:,1:] \n",
    "\n",
    "Just be aware that this will make your output 3D. If you're interested only in the last word, you can manually take it from the output: lastWord = outputs[:,-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
