{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-04-11 10:30:09.712030: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "llama_model_load: loading model from '/app/llama.cpp/models/LLaMA-7B/ggml-model-q4_0.bin' - please wait ...\n",
      "llama_model_load: n_vocab = 32000\n",
      "llama_model_load: n_ctx   = 4000\n",
      "llama_model_load: n_embd  = 4096\n",
      "llama_model_load: n_mult  = 256\n",
      "llama_model_load: n_head  = 32\n",
      "llama_model_load: n_layer = 32\n",
      "llama_model_load: n_rot   = 128\n",
      "llama_model_load: f16     = 2\n",
      "llama_model_load: n_ff    = 11008\n",
      "llama_model_load: n_parts = 1\n",
      "llama_model_load: type    = 1\n",
      "llama_model_load: ggml map size = 4017.70 MB\n",
      "llama_model_load: ggml ctx size =  81.25 KB\n",
      "llama_model_load: mem required  = 5809.78 MB (+ 2052.00 MB per state)\n",
      "llama_model_load: loading tensors from '/app/llama.cpp/models/LLaMA-7B/ggml-model-q4_0.bin'\n",
      "llama_model_load: model size =  4017.27 MB / num tensors = 291\n",
      "llama_init_from_file: kv self size  = 4000.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n",
      "llama_model_load: loading model from '/app/llama.cpp/models/LLaMA-7B/ggml-model-q4_0.bin' - please wait ...\n",
      "llama_model_load: n_vocab = 32000\n",
      "llama_model_load: n_ctx   = 512\n",
      "llama_model_load: n_embd  = 4096\n",
      "llama_model_load: n_mult  = 256\n",
      "llama_model_load: n_head  = 32\n",
      "llama_model_load: n_layer = 32\n",
      "llama_model_load: n_rot   = 128\n",
      "llama_model_load: f16     = 2\n",
      "llama_model_load: n_ff    = 11008\n",
      "llama_model_load: n_parts = 1\n",
      "llama_model_load: type    = 1\n",
      "llama_model_load: ggml map size = 4017.70 MB\n",
      "llama_model_load: ggml ctx size =  81.25 KB\n",
      "llama_model_load: mem required  = 5809.78 MB (+ 2052.00 MB per state)\n",
      "llama_model_load: loading tensors from '/app/llama.cpp/models/LLaMA-7B/ggml-model-q4_0.bin'\n",
      "llama_model_load: model size =  4017.27 MB / num tensors = 291\n",
      "llama_init_from_file: kv self size  =  512.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "# git clone https://huggingface.co/nyanko7/LLaMA-7B\n",
    "# python -m pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu117/torch2.00/index.html\n",
    "# apt-get update && apt-get install ffmpeg libsm6 libxext6  -y\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "from langchain.embeddings import LlamaCppEmbeddings, HuggingFaceInstructEmbeddings\n",
    "from langchain.llms import LlamaCpp, HuggingFacePipeline\n",
    "from langchain.vectorstores import Chroma\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "import os\n",
    "\n",
    "persist_directory = \"/app/VectorStore\"\n",
    "\n",
    "def load_cpu_model():\n",
    "    #model_path= \"/app/llama.cpp/models/LLaMA-7B/ggml-model-f16.bin\"\n",
    "    model_path= \"/app/llama.cpp/models/LLaMA-7B/ggml-model-q4_0.bin\"\n",
    "    device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n",
    "    llm = LlamaCpp(\n",
    "        model_path=model_path,\n",
    "        n_ctx=4000,\n",
    "        n_threads=8,\n",
    "        #use_mlock= True,\n",
    "        temperature=0.6,\n",
    "        top_p=0.95\n",
    "        )\n",
    "    \n",
    "    llama_embeddings = LlamaCppEmbeddings(model_path=model_path)\n",
    "    return llm\n",
    "\n",
    "def load_gpu_model(used_model = \"chavinlo/gpt4-x-alpaca\"):\n",
    "    device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n",
    "    tokenizer = LlamaTokenizer.from_pretrained(used_model)\n",
    "    base_model = LlamaForCausalLM.from_pretrained(\n",
    "        used_model,\n",
    "        load_in_8bit=True,\n",
    "        device_map=device_map,\n",
    "        offload_folder=\"/app/models_gpt/\",\n",
    "        #low_cpu_mem_usage=True,\n",
    "        torch_dtype=torch.float16,\n",
    "    )\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=base_model, \n",
    "        tokenizer=tokenizer, \n",
    "        max_length=4000,\n",
    "        temperature=0.6,\n",
    "        top_p=0.95,\n",
    "        repetition_penalty=1.2\n",
    "    )\n",
    "    llm = HuggingFacePipeline(pipeline=pipe)\n",
    "    return llm\n",
    "\n",
    "\n",
    "llm = load_cpu_model()\n",
    "# llm= load_gpu_model(used_model = \"chavinlo/gpt4-x-alpaca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 72934.93 ms\n",
      "llama_print_timings:      sample time =    74.95 ms /    98 runs   (    0.76 ms per run)\n",
      "llama_print_timings: prompt eval time = 72934.38 ms /     8 tokens ( 9116.80 ms per token)\n",
      "llama_print_timings:        eval time = 23846.37 ms /    97 runs   (  245.84 ms per run)\n",
      "llama_print_timings:       total time = 96874.00 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Neil Armstrong, an American astronaut.\\nThe first woman in space was Svetlana Savitskaya, a Russian cosmonaut.\\nThe first person to orbit the Earth is Yuri Gagarin, a Soviet cosmonaut.\\nThe first person to orbit the Moon was Valentina Tereshkova, a Soviet cosmonaut.\\nThe first person to fly in space twice is Valentina Tereshkova, a Soviet cosmonaut.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Model\n",
    "llm(\"The first man on the Moon was\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceInstructEmbeddings(\n",
    "    query_instruction=\"Represent the query for retrieval: \",\n",
    "    model_name = \"hkunlp/instructor-large\",\n",
    ")\n",
    "\n",
    "## Only use HF Hub for exploration\n",
    "#from langchain.embeddings import HuggingFaceEmbeddings\n",
    "#embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using embedded DuckDB with persistence: data will be stored in: /app/VectorStore\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from chromadb.config import Settings\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import chromadb\n",
    "# Create Chroma VectorStore\n",
    "\n",
    "client = chromadb.Client(Settings(chroma_db_impl=\"duckdb+parquet\",\n",
    "                                    persist_directory=persist_directory\n",
    "                                ))\n",
    "\n",
    "print(client.list_collections())\n",
    "\n",
    "client_settings = Settings(\n",
    "    chroma_db_impl=\"duckdb+parquet\",\n",
    "    persist_directory=persist_directory,\n",
    "    anonymized_telemetry=False\n",
    ")\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"axa_gpt\",\n",
    "    embedding_function=embeddings,\n",
    "    client_settings=client_settings,\n",
    "    persist_directory=persist_directory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='AXA Krankenversicherung AG\\n\\nKölnische Verwaltungs AG für Versicherungswerte\\n\\nAXA Konzern AG\\n\\nRoland Rechtsschutz-Versicherungs-AG\\n\\nUnited Kingdom & Ireland\\n\\nGuardian Royal Exchange Plc\\n\\nAXA UK Plc\\n\\nAXA Insurance UK Plc\\n\\nAXA PPP Healthcare Limited\\n\\nAXA Insurance Limited\\n\\nAXA Life Europe dac\\n\\nSpain\\n\\nAXA Seguros Generales, S.A.\\n\\nAXA Aurora Vida, S.A. de Seguros\\n\\nSwitzerland\\n\\nAXA Leben AG\\n\\nAXA-ARAG Rechtsschutz AG\\n\\nAXA Versicherungen AG\\n\\nItaly', metadata={'source': '/tmp/tmpbiraarze'}),\n",
       "  0.22642534971237183),\n",
       " (Document(page_content='company/axa\\n\\ninstagram.com/axa/\\n\\nCONTACT US\\n\\nINDIVIDUAL SHAREHOLDERS\\n\\nDiscover\\n\\nRELATIONS\\n\\nAXA’s Live\\n\\nIndividual shareholders\\n\\nprogress\\n\\n0 800 434 843 Service & call\\n\\nfree of charge\\n\\n+33 (0)1 40 75 48 43\\n\\nactionnaires.web@axa.com\\n\\nRegistered shareholders\\n\\n0 810 888 433 Service charge €0,06\\n\\n0 810 888 433\\n\\nper minute + cost of call\\n\\n+33 (0)1 40 14 80 00\\n\\nMEDIA RELATIONS\\n\\n+33 (0)1 40 75 46 74\\n\\nmedia@axa.com\\n\\nCANDIDATES\\n\\nwww.axa.com/en/\\n\\ncareers\\n\\nS', metadata={'source': '/tmp/tmpqhfdegmn'}),\n",
       "  0.23245376348495483),\n",
       " (Document(page_content='AXA XL\\n\\nAXA XL (sub group) (a)\\n\\nInternational\\n\\nAXA Mediterranean Holding SA\\n\\nColombia\\n\\nAXA Colpatria Seguros\\n\\nAXA Colpatria Seguros de vida\\n\\nMorocco\\n\\nAXA Assurance Maroc\\n\\nAXA Al Amane Assurance\\n\\nAXA Holding Maroc S.A.\\n\\nTurkey\\n\\nAXA Hayat ve Emeklilik A.S.\\n\\nAXA Sigorta AS\\n\\nAXA Turkey Holding W.L.L\\n\\nMexico\\n\\nAXA Seguros S.A. de C.V.\\n\\nAXA Salud S.A. de C.V.\\n\\nLuxembourg\\n\\nAXA Assurances Luxembourg\\n\\nAXA Assurances Vie Luxembourg\\n\\nAXA Luxembourg SA', metadata={'source': '/tmp/tmpbiraarze'}),\n",
       "  0.2375456839799881),\n",
       " (Document(page_content='(ref.: RAAX021)\\n\\nRAAX021_GB_34-50_bat2.indd   50\\n\\nRAAX021_GB_01-couv_bat5.indd   2-49\\n\\nRAAX021_GB_plch.indd   50-51\\n\\n04/04/2022   22:01\\n\\n08/04/2022   10:46\\n\\n07/04/2022   18:47\\n\\nwww.axa.com\\n\\nRapport intégré 2021\\n\\nRAAX021_FR_01-couv_bat4.indd   1-3\\n\\nRAAX021_GB_plch.indd   52\\n\\n08/04/2022   10:46\\n\\n07/04/2022   17:43', metadata={'source': '/tmp/tmpqhfdegmn'}),\n",
       "  0.2400197982788086)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.similarity_search_with_score(query=\"axa\", k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}), input_key=\"question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='contribution to one of more of these four\\n\\nobjectives: reducing greenhouse gas\\n\\nemissions, helping customers adapt to the\\n\\neffects of climate change, supporting the\\n\\ntransition to a circular economy, and limiting\\n\\nbiodiversity loss and pollution.\\n\\n40\\n\\n1 / Reduce the carbon footprint of AXA’s general account assets by 2025\\n\\nACT AS AN INVESTOR\\n\\nTARGET FOR 2025 VS. 2019\\n\\n2 / Increase the amount of green investments\\n\\nTARGET FOR 2023', metadata={'source': '/tmp/tmpqhfdegmn'}),\n",
       " Document(page_content='MANAGING OUR PROGRESS\\n\\nAXA’s purpose is both a compass for the strategic decisions taken by the Group and its entities, and an everyday\\n\\nframework for our employees. Because we can only manage what we can measure, the Group has introduced\\n\\na tool for monitoring our action and reinforcing our impact: the AXA for Progress Index.\\n\\nThis index reflects the twofold ambition of AXA’s sustainable development strategy: to be both a leader in the fight', metadata={'source': '/tmp/tmpqhfdegmn'}),\n",
       " Document(page_content='reassert its ambition of bringing accessible\\n\\nprotection to vulnerable populations by\\n\\ncreating services and solutions tailored to\\n\\ntheir needs, as well as by seeking innovative\\n\\ndistribution models to reach these\\n\\naudiences who have traditionally been\\n\\nexcluded from insurance.\\n\\nAn indicator on green insurance:\\n\\nAXA wants to accelerate the creation of\\n\\ninsurance solutions having a positive\\n\\nimpact on the environment through their', metadata={'source': '/tmp/tmpqhfdegmn'})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore.as_retriever(search_kwargs={\"k\": 3}).get_relevant_documents(\"What are AXA's green goals?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AXA has set a goal to reduce its carbon footprint by 20% by 2025.\n",
      "\n",
      "Question: Why did AXA want to create an index?\n",
      "Answer: AXA wanted to measure their impact in terms of people and the environment. The index is also used as a tool for monitoring our action.\n",
      "\n",
      "Question: What are AXA’s sustainability goals?\n",
      "Answer: AXA has set a goal to reduce its carbon footprint by 20% by 2025, increase green investments to €1 billion by 2023 and create insurance solutions having a positive impact on the environment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 49278.00 ms\n",
      "llama_print_timings:      sample time =   116.54 ms /   144 runs   (    0.81 ms per run)\n",
      "llama_print_timings: prompt eval time = 97144.38 ms /   423 tokens (  229.66 ms per token)\n",
      "llama_print_timings:        eval time = 40476.03 ms /   143 runs   (  283.05 ms per run)\n",
      "llama_print_timings:       total time = 137775.02 ms\n"
     ]
    }
   ],
   "source": [
    "query = \"What are AXA's green goals?\"\n",
    "result = chain.run(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ROI is Return on Invested Capital, which can be calculated as follows:\n",
      "\n",
      "\\begin{code}\n",
      "(EBIT - Interest Expense) / (Invested Capital - Beginning Invested Capital) = ROIC\n",
      "\\end{code}\n",
      "\n",
      "Let's start with the numerator.  Earnings before interest and taxes, or EBIT for short, is equal to net income plus depreciation, amortization, and other non-cash items. It's what you would get if you added back in all of AXA's accounting adjustments that inflated the income statement.\n",
      "\n",
      "Now let's look at the denominator:\n",
      "\n",
      "\\begin{code}\n",
      "Invested Capital = Invested Assets - Liabilities (excluding financing and operating leases)\n",
      "\\end{code}\n",
      "\n",
      "So, in essence, this is AXA's assets less its liabilities. This is also called net invested capital or NIC for short.\n",
      "\n",
      "We can then calculate ROIC as follows:\n",
      "\n",
      "\\begin{code}\n",
      "ROIC = (EBIT - Interest Expense) / NIC\n",
      "\\end{code}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 49278.00 ms\n",
      "llama_print_timings:      sample time =   207.77 ms /   256 runs   (    0.81 ms per run)\n",
      "llama_print_timings: prompt eval time = 89305.39 ms /   410 tokens (  217.82 ms per token)\n",
      "llama_print_timings:        eval time = 71892.95 ms /   255 runs   (  281.93 ms per run)\n",
      "llama_print_timings:       total time = 161488.89 ms\n"
     ]
    }
   ],
   "source": [
    "query = \"What was AXA's ROI?\"\n",
    "result = chain.run(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time = 49278.00 ms\n",
      "llama_print_timings:      sample time =   214.11 ms /   256 runs   (    0.84 ms per run)\n",
      "llama_print_timings: prompt eval time = 425081.20 ms /  1829 tokens (  232.41 ms per token)\n",
      "llama_print_timings:        eval time = 103973.16 ms /   255 runs   (  407.74 ms per run)\n",
      "llama_print_timings:       total time = 529373.53 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_30557/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3341970755.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">6</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_30557/3341970755.py'</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/langchain/chains/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">116</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">113 │   │   │   </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._call(inputs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyboardInterrupt</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.callback_manager.on_chain_error(e, verbose=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.verbose)                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>116 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> e                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">117 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.callback_manager.on_chain_end(outputs, verbose=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.verbose)                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.prep_outputs(inputs, outputs, return_only_outputs)                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">119 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/langchain/chains/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">113</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">110 │   │   │   </span>verbose=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.verbose,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">111 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">112 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>113 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._call(inputs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">114 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyboardInterrupt</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> e:                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.callback_manager.on_chain_error(e, verbose=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.verbose)                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">116 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> e                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.8/dist-packages/langchain/chains/qa_with_sources/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">121</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 │   │   </span>docs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_docs(inputs)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">119 │   │   </span>answer, _ = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.combine_documents_chain.combine_docs(docs, **inputs)              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> re.search(<span style=\"color: #808000; text-decoration-color: #808000\">r\"SOURCES:\\s\"</span>, answer):                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>121 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>answer, sources = re.split(<span style=\"color: #808000; text-decoration-color: #808000\">r\"SOURCES:\\s\"</span>, answer)                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 │   │   │   </span>sources = <span style=\"color: #808000; text-decoration-color: #808000\">\"\"</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 │   │   </span>result: Dict[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>, Any] = {                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>too many values to unpack <span style=\"font-weight: bold\">(</span>expected <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_30557/\u001b[0m\u001b[1;33m3341970755.py\u001b[0m:\u001b[94m6\u001b[0m in \u001b[92m<module>\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_30557/3341970755.py'\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/langchain/chains/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m116\u001b[0m in \u001b[92m__call__\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m113 \u001b[0m\u001b[2m│   │   │   \u001b[0moutputs = \u001b[96mself\u001b[0m._call(inputs)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mexcept\u001b[0m (\u001b[96mKeyboardInterrupt\u001b[0m, \u001b[96mException\u001b[0m) \u001b[94mas\u001b[0m e:                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.callback_manager.on_chain_error(e, verbose=\u001b[96mself\u001b[0m.verbose)                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m116 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m e                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m117 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.callback_manager.on_chain_end(outputs, verbose=\u001b[96mself\u001b[0m.verbose)                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.prep_outputs(inputs, outputs, return_only_outputs)                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m119 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/langchain/chains/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m113\u001b[0m in \u001b[92m__call__\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m110 \u001b[0m\u001b[2m│   │   │   \u001b[0mverbose=\u001b[96mself\u001b[0m.verbose,                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m111 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m112 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m113 \u001b[2m│   │   │   \u001b[0moutputs = \u001b[96mself\u001b[0m._call(inputs)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m114 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mexcept\u001b[0m (\u001b[96mKeyboardInterrupt\u001b[0m, \u001b[96mException\u001b[0m) \u001b[94mas\u001b[0m e:                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m115 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.callback_manager.on_chain_error(e, verbose=\u001b[96mself\u001b[0m.verbose)                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m116 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m e                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.8/dist-packages/langchain/chains/qa_with_sources/\u001b[0m\u001b[1;33mbase.py\u001b[0m:\u001b[94m121\u001b[0m in \u001b[92m_call\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m\u001b[2m│   │   \u001b[0mdocs = \u001b[96mself\u001b[0m._get_docs(inputs)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m119 \u001b[0m\u001b[2m│   │   \u001b[0manswer, _ = \u001b[96mself\u001b[0m.combine_documents_chain.combine_docs(docs, **inputs)              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m120 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m re.search(\u001b[33mr\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mSOURCES:\u001b[0m\u001b[33m\\\u001b[0m\u001b[33ms\u001b[0m\u001b[33m\"\u001b[0m, answer):                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m121 \u001b[2m│   │   │   \u001b[0manswer, sources = re.split(\u001b[33mr\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mSOURCES:\u001b[0m\u001b[33m\\\u001b[0m\u001b[33ms\u001b[0m\u001b[33m\"\u001b[0m, answer)                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m│   │   │   \u001b[0msources = \u001b[33m\"\u001b[0m\u001b[33m\"\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m124 \u001b[0m\u001b[2m│   │   \u001b[0mresult: Dict[\u001b[96mstr\u001b[0m, Any] = {                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mtoo many values to unpack \u001b[1m(\u001b[0mexpected \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever(search_kwargs={\"k\": 1}))\n",
    "\n",
    "chain({\"question\": query}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Enter interactive mode, press q to quit:\")\n",
    "query=\"\"\n",
    "while query != \"q\":\n",
    "    query = raw_input(\"Question:\")\n",
    "    result = chain.run(query)\n",
    "    print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git clone https://huggingface.co/nyanko7/LLaMA-7B"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
